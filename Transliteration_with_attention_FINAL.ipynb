{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTK4IFUhLr8N"
      },
      "source": [
        "### Importing Libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apeRGrBs6yH8"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import tensorflow \n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, GRU, Dropout, SimpleRNN\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from math import log\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from math import log1p "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NsYPEEpM5cU",
        "outputId": "df7b7a36-cbbb-4d3a-a073-98c2683e1cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 39.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 36.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install wandb -q\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6lJCkKMLwDe"
      },
      "source": [
        "### Unzipping the dataset\n",
        "\n",
        "Lexicons for Latin-Telugu are taken from Google's Dakshina dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhpFjBqec5sk",
        "outputId": "a6a87132-4e2e-4785-f69f-0a369414cc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-07 19:24:56--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.6.128, 142.250.152.128, 142.251.120.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.6.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G  73.0MB/s    in 15s     \n",
            "\n",
            "2022-05-07 19:25:11 (127 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloading dakshina dataset\n",
        "!yes | wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8V3WTrkfF66"
      },
      "outputs": [],
      "source": [
        "# Unzipping dataset\n",
        "!yes | tar xopf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9IlHm7CfO_I",
        "outputId": "b1a2465a-0063-40cf-c0c1-b94f4b6a160e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "te.translit.sampled.dev.tsv   te.translit.sampled.train.tsv\n",
            "te.translit.sampled.test.tsv\n"
          ]
        }
      ],
      "source": [
        "# The folder containing the datasets to be used in this program\n",
        "!ls dakshina_dataset_v1.0/te/lexicons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x95CxiMFl54"
      },
      "outputs": [],
      "source": [
        "from matplotlib.font_manager import FontProperties\n",
        "tel_font = FontProperties(fname = Mandali-Regular.ttf') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPoGXywuL1kD"
      },
      "source": [
        "## Reading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBzvL2e20Sx-",
        "outputId": "be3c7c8d-e8b2-4ace-a772-4a3ea7dc49a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  58550\n",
            "Number of validation samples:  5683\n",
            "Number of testing samples:  5683\n"
          ]
        }
      ],
      "source": [
        "train_path = \"./dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv\"\n",
        "dev_path = \"./dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\"\n",
        "test_path = \"./dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.test.tsv\"\n",
        "\n",
        "def reading_data(corpus_file):\n",
        "  # function reads the raw text of words and returns native versions of words\n",
        "  telugu_words = []\n",
        "  latin_words = []\n",
        "  with io.open(corpus_file, encoding ='utf-8') as f:\n",
        "    for line in f:\n",
        "      if '\\t' not in line:\n",
        "        continue\n",
        "      tokens = line.rstrip().split(\"\\t\")\n",
        "      latin_words.append(tokens[1])\n",
        "      telugu_words.append(tokens[0])\n",
        "  return latin_words, telugu_words\n",
        "\n",
        "train_source, train_target = reading_data(train_path)\n",
        "val_source, val_target = reading_data(dev_path)\n",
        "test_source, test_target = reading_data(test_path)\n",
        "\n",
        "print(\"Number of training samples: \", len(train_source))\n",
        "print(\"Number of validation samples: \", len(val_source))\n",
        "print(\"Number of testing samples: \", len(test_source))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mC2ICFKRUZA"
      },
      "outputs": [],
      "source": [
        "arr = np.arange(len(train_source))\n",
        "np.random.shuffle(arr)\n",
        "arr1 = np.arange(len(val_source))\n",
        "np.random.shuffle(arr1)\n",
        "\n",
        "input_chars = set()\n",
        "target_chars = set()\n",
        "input_lexicons_nextstep = []\n",
        "target_lexicons_nextstep = []\n",
        "val_input_lexicons_nextstep = []\n",
        "val_target_lexicons_nextstep = []\n",
        "\n",
        "for (input_text, target_text) in zip(train_source, train_target):\n",
        "    # \"tab\" is the \"start sequence\" characte ,\"\\n\" is \"end sequence\" character.\n",
        "    target_text = \"B\" + target_text + \"E\"\n",
        "    input_lexicons_nextstep.append(input_text)\n",
        "    target_lexicons_nextstep.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_chars:\n",
        "            input_chars.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_chars:\n",
        "            target_chars.add(char)\n",
        "\n",
        "for (input_text, target_text) in zip(val_source, val_target):\n",
        "    # \"tab\" is the \"start sequence\" character ,\"\\n\" is \"end sequence\" character.\n",
        "    target_text = \"B\" + target_text + \"E\"\n",
        "    val_input_lexicons_nextstep.append(input_text)\n",
        "    val_target_lexicons_nextstep.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_chars:\n",
        "            input_chars.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_chars:\n",
        "            target_chars.add(char)\n",
        "\n",
        "input_lexicons = []\n",
        "target_lexicons = []\n",
        "\n",
        "for i in range(len(train_source)):\n",
        "    input_lexicons.append(input_lexicons_nextstep[arr[i]])\n",
        "    target_lexicons.append(target_lexicons_nextstep[arr[i]])\n",
        "\n",
        "val_input_lexicons = []\n",
        "val_target_lexicons = []\n",
        "\n",
        "for i in range(len(val_source)):\n",
        "    val_input_lexicons.append(val_input_lexicons_nextstep[arr1[i]])\n",
        "    val_target_lexicons.append(val_target_lexicons_nextstep[arr1[i]])\n",
        "\n",
        "input_chars.add(\" \")\n",
        "target_chars.add(\" \")\n",
        "\n",
        "input_chars = sorted(list(input_chars))\n",
        "target_chars = sorted(list(target_chars))\n",
        "\n",
        "\n",
        "no_enc_tokens = len(input_chars)\n",
        "no_dec_tokens = len(target_chars)\n",
        "enc_seq_length = max([len(txt) for txt in input_lexicons])\n",
        "dec_seq_length = max([len(txt) for txt in target_lexicons])\n",
        "val_max_encoder_seq_length = max([len(txt) for txt in val_input_lexicons])\n",
        "val_max_decoder_seq_length = max([len(txt) for txt in val_target_lexicons])\n",
        "\n",
        "\n",
        "\n",
        "print(\"No of samples:\", len(input_lexicons))\n",
        "print(\"No of unique input tokens:\", no_enc_tokens)\n",
        "print(\"No of unique output tokens:\", no_dec_tokens)\n",
        "print(\"Maximum sequence length for inputs:\", enc_seq_length)\n",
        "print(\"Maximum sequence length for outputs:\", dec_seq_length)\n",
        "print(\"Maximum sequence length for val inputs:\", val_max_encoder_seq_length)\n",
        "print(\"Maximum sequence length for val outputs:\", val_max_decoder_seq_length)\n",
        "\n",
        "print(input_chars)\n",
        "print(target_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwPNb93PRwHT"
      },
      "source": [
        "**Training** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtHaPQPw6VuP"
      },
      "outputs": [],
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_chars)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_chars)])\n",
        "print(input_token_index)\n",
        "print(target_token_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3i7ykYbtQ2K"
      },
      "outputs": [],
      "source": [
        "# Encoder Input Sequences are padded to a maximum length of MAX encoder SeqLen characters. \n",
        "enc_input_data = np.zeros(\n",
        "    (len(input_lexicons), enc_seq_length), dtype=\"float32\"\n",
        ")\n",
        "dec_input_data = np.zeros(\n",
        "    (len(input_lexicons), dec_seq_length), dtype=\"float32\"\n",
        ")\n",
        "dec_target_data = np.zeros(\n",
        "    (len(input_lexicons), dec_seq_length, no_dec_tokens), dtype=\"float32\"\n",
        ")\n",
        "#Decoder Target Sequences are Padded to a maximum length of max_decoder SeqLen characters with a vocabulary of sizeofTeluguVocab different characters. \n",
        "for i, (input_text, target_text) in enumerate(zip(input_lexicons, target_lexicons)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        enc_input_data[i, t] = input_token_index[char]\n",
        "    enc_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "\n",
        "    for t, char in enumerate(target_text):\n",
        "        # dec_target_data is ahead of dec_input_data by one timestep\n",
        "        dec_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # dec_target_data will not include the start character.\n",
        "            dec_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    dec_input_data[i, t + 1: ] = target_token_index[\" \"]\n",
        "    dec_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "\n",
        "val_enc_input_data = np.zeros(\n",
        "    (len(input_lexicons), val_max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_dec_input_data = np.zeros(\n",
        "    (len(input_lexicons), val_max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_dec_target_data = np.zeros(\n",
        "    (len(input_lexicons), val_max_decoder_seq_length, no_dec_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(val_input_lexicons, val_target_lexicons)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        # Enumerate() method adds a counter to an iterable and returns it in a form of enumerating object. \n",
        "        # This enumerated object can then be used directly for loops or converted into a list of tuples using the list() method.\n",
        "        val_enc_input_data[i, t] = input_token_index[char]\n",
        "    val_enc_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "\n",
        "    for t, char in enumerate(target_text):\n",
        "        val_dec_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # dec_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            val_dec_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    val_dec_input_data[i, t + 1: ] = target_token_index[\" \"]\n",
        "    val_dec_target_data[i, t:, target_token_index[\" \"]] = 1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOUdwNGG39qb"
      },
      "outputs": [],
      "source": [
        "# Feeding the characters in reverse order (bidirectional) for better processing\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "print(reverse_target_char_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui9pFxRvSdeT"
      },
      "source": [
        "For Validation and testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7q6xNssrRwb"
      },
      "outputs": [],
      "source": [
        "x_test = val_enc_input_data\n",
        "y_test = val_target_lexicons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape = tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer = 'uniform',\n",
        "                                   trainable = True)\n",
        "\n",
        "        self.U_a = self.add_weight(name = 'U_a',\n",
        "                                   shape = tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer = 'uniform',\n",
        "                                   trainable = True)\n",
        "\n",
        "        self.V_a = self.add_weight(name = 'V_a',\n",
        "                                   shape = tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer = 'uniform',\n",
        "                                   trainable = True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs):\n",
        "       \n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "           \n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "            \n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n"
      ],
      "metadata": {
        "id": "aXgEHRqHSYPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL TRAINING "
      ],
      "metadata": {
        "id": "fsl1l9XK_jm0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvI1fI7UOPMT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class RNN_Attn(object):\n",
        "  def __init__(self,cell_type = 'RNN',in_emb = 32, hidden_size=32, learning_rate= 1e-3, \n",
        "               dropout=0.4,epochs = 10, batch_size = 32,\n",
        "               num_enc = 1,num_dec = 1):\n",
        "    \n",
        "    self.cell_type = cell_type\n",
        "    self.in_emb = in_emb\n",
        "    self.hidden_size = hidden_size\n",
        "    self.learning_rate = learning_rate\n",
        "    self.dropout = dropout\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.num_enc = num_enc\n",
        "    self.num_dec = num_dec\n",
        "\n",
        "  def build(self,enc_input_data,dec_input_data,dec_target_data,x_test, y_test):\n",
        "    enc_inputs = Input(shape=(None, ),name = 'Enc_inputs')\n",
        "\n",
        "    # Add an Embedding layer expecting input vocab of size no_enc_tokens, and\n",
        "    # output embedding dimension of size in_enc.\n",
        "    enc_emb =  Embedding(no_enc_tokens, self.in_emb , mask_zero = True,name = 'Enc_emb')(enc_inputs)\n",
        "\n",
        "    enc_outputs = enc_emb\n",
        "    if self.cell_type == 'LSTM':\n",
        "      encoder_lstm = LSTM(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "      enc_outputs, state_h, state_c = encoder_lstm(enc_outputs)\n",
        "      encoder_states = [state_h, state_c]\n",
        "      encoder_first_outputs = enc_outputs\n",
        "\n",
        "      # Add a LSTM layer with hidden_size internal units.\n",
        "      for i in range( 2, self.num_enc +1):\n",
        "        layer_name = ('Enc_hidden_%d') %i\n",
        "        encoder_lstm = LSTM(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "        enc_outputs, state_h, state_c = encoder_lstm(enc_outputs,initial_state = encoder_states)\n",
        "        encoder_states = [state_h, state_c]\n",
        "\n",
        "    elif self.cell_type == 'GRU':\n",
        "      encoder_gru = GRU(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "      enc_outputs, state_h = encoder_gru(enc_outputs)\n",
        "      encoder_states = [state_h]\n",
        "      encoder_first_outputs = enc_outputs\n",
        "\n",
        "      for i in range(2, self.num_enc +1):\n",
        "        layer_name = ('Enc_hidden_%d') %i\n",
        "        encoder_gru = GRU(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "        enc_outputs, state_h = encoder_gru(enc_outputs, initial_state = encoder_states)\n",
        "        encoder_states = [state_h]  \n",
        "\n",
        "    elif self.cell_type == 'RNN':\n",
        "      encoder_rnn = SimpleRNN(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "      enc_outputs, state_h = encoder_rnn(enc_outputs)\n",
        "      encoder_states = [state_h]\n",
        "      encoder_first_outputs = enc_outputs\n",
        "\n",
        "      for i in range(2, self.num_enc +1):\n",
        "        layer_name = ('Enc_hidden_%d') %i\n",
        "        encoder_rnn = SimpleRNN(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "        enc_outputs, state_h = encoder_rnn(enc_outputs, initial_state = encoder_states)\n",
        "        encoder_states = [state_h]  \n",
        "\n",
        "    # Set up the decoder, using `encoder_states` as initial state.\n",
        "    dec_inputs = Input(shape=(None,), name = 'Dec_inputs')\n",
        "    dec_emb_layer = Embedding(no_dec_tokens, self.hidden_size, mask_zero = True, name = 'Dec_emb')\n",
        "    dec_emb = dec_emb_layer(dec_inputs)\n",
        "    # We set up our decoder to return full output sequences,\n",
        "    # and to return internal states as well. We don't use the\n",
        "    # return states in the training model, but we will use them in inference.\n",
        "    dec_outputs = dec_emb\n",
        "    decoder_first_outputs = dec_outputs\n",
        "    if self.cell_type == 'LSTM':\n",
        "      decoder_lstm = LSTM(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "      dec_outputs, _, _ = decoder_lstm(dec_outputs, initial_state = encoder_states)\n",
        "      \n",
        "      for i in range(2, self.num_dec +1):\n",
        "        layer_name = ('Dec_hidden_%d') %i\n",
        "        decoder_lstm = LSTM(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "        dec_outputs, _, _ = decoder_lstm(dec_outputs, initial_state = encoder_states)\n",
        "        if i == self.num_dec:\n",
        "          decoder_first_outputs = dec_outputs\n",
        "\n",
        "    elif self.cell_type == 'GRU':\n",
        "      decoder_gru = GRU(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "      dec_outputs, _ = decoder_gru(dec_outputs, initial_state = encoder_states)\n",
        "\n",
        "      for i in range(2, self.num_dec+1):\n",
        "        layer_name = ('Dec_hidden_%d') %i\n",
        "        decoder_gru = GRU(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "        dec_outputs, _ = decoder_gru(dec_outputs, initial_state = encoder_states)\n",
        "        if i == self.num_dec:\n",
        "          decoder_first_outputs = dec_outputs\n",
        "\n",
        "    elif self.cell_type == 'RNN':\n",
        "      decoder_rnn = SimpleRNN(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "      dec_outputs, _ = decoder_rnn(dec_outputs, initial_state = encoder_states)\n",
        "\n",
        "      for i in range(2, self.num_dec+1):\n",
        "        layer_name = ('Dec_hidden_%d') %i\n",
        "        decoder_rnn = SimpleRNN(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "        dec_outputs, _ = decoder_rnn(dec_outputs, initial_state = encoder_states)\n",
        "        if i == self.num_dec:\n",
        "          decoder_first_outputs = dec_outputs\n",
        "\n",
        "    attention_layer = AttentionLayer(name='attention_layer')\n",
        "    attention_out, attention_states = attention_layer([enc_outputs, dec_outputs])\n",
        "\n",
        "    decoder_concat_input = keras.layers.Concatenate(axis=-1, name='concat_layer')([dec_outputs, attention_out])\n",
        "\n",
        "    decoder_dense = Dense(no_dec_tokens, activation='softmax', name = 'dense')\n",
        "    dec_outputs = decoder_dense(dec_outputs)\n",
        "\n",
        "    # Define the model that takes encoder and decoder input \n",
        "    # to output dec_outputs\n",
        "    model = Model([enc_inputs, dec_inputs], dec_outputs)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy'])\n",
        "  \n",
        "    model.fit(\n",
        "        [enc_input_data, dec_input_data],\n",
        "        dec_target_data,\n",
        "        batch_size=self.batch_size,\n",
        "        epochs=self.epochs,\n",
        "        callbacks = [WandbCallback()]\n",
        "        )\n",
        "    \n",
        "    pred=model.predict(val_enc_input_data[:5500], batch_size=self.batch_size)\n",
        "\n",
        "    global_count = 0\n",
        "    count = 0\n",
        "    global_total = 0\n",
        "    global_correct = 0\n",
        "    val_total = 5500\n",
        "    for index in range(0, val_total):\n",
        "      one_hot_vector = pred[index]\n",
        "      one_hot_vector1 = val_dec_target_data[index]\n",
        "      index2 = tf.argmax(one_hot_vector, axis=1)\n",
        "      index1 = tf.argmax(one_hot_vector1, axis=1)\n",
        "      #a = (index2-index1).numpy()\n",
        "      if (index2.numpy() == index1.numpy()).all():\n",
        "        global_correct = global_correct + 1\n",
        "        \n",
        "      global_total = global_total + 1\n",
        "      accuracy_epoch = global_correct/global_total\n",
        "      if global_total % 50 == 0:\n",
        "        wandb.log({'epoch_accuracy' : accuracy_epoch})\n",
        "      #print(\"Accuracy: %s\" % (accuracy_epoch))\n",
        "    \n",
        "    val_accuracy = global_correct/global_total\n",
        "    #print(val_accuracy)\n",
        "\n",
        "    wandb.log({'val_accuracy' : val_accuracy})\n",
        "\n",
        "    model.save(os.path.join(\"./TestedAttentionModels\", wandb.run.name))    \n",
        "    wandb.finish() \n",
        "\n",
        "  def evaluate(self,seq_in):\n",
        "    attention_plot = np.zeros((max_decoder_seq_length, max_encoder_seq_length))\n",
        "    sequence = seq_in\n",
        "    encoder_inputs=array(sequence).reshape(1,max_encoder_seq_length,num_encoder_tokens)\n",
        "    \n",
        "    encoder_inputs = tf.convert_to_tensor(encoder_inputs,dtype=tf.float32)\n",
        "    \n",
        "    if self.cell_type == 'LSTM':\n",
        "      encoder_outputs, encoder_state_h, encoder_state_c = encoder(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h, encoder_state_c]\n",
        "    elif self.cell_type == 'GRU':\n",
        "      encoder_outputs, encoder_state_h = encoder(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h]\n",
        "    elif self.cell_type == 'RNN':\n",
        "      encoder_outputs, encoder_state_h = encoder(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h]\n",
        "\n",
        "    all_outputs = []\n",
        "\n",
        "    decoder_input_data = np.zeros((1, 1, num_decoder_tokens))\n",
        "    decoder_input_data[:, 0, 0] = 1 \n",
        "\n",
        "    inputs = decoder_input_data\n",
        "    decoder_outputs = encoder_state_h\n",
        "    states = encoder_states\n",
        "\n",
        "    weigh_atten =[]\n",
        "    for t in range(max_decoder_seq_length):\n",
        "\n",
        "      # pay attention\n",
        "      context_vector, attention_weights=attention(decoder_outputs, encoder_outputs)\n",
        "\n",
        "      # storing the attention weights to plot later on\n",
        "      attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "      weigh_atten.append(attention_weights)\n",
        "      \n",
        "      attention_plot[t] = attention_weights.numpy()\n",
        "      \n",
        "      decoder_outputs=tf.expand_dims(decoder_outputs, 1)\n",
        "\n",
        "      context_vector = tf.expand_dims(context_vector, 1)\n",
        "      inputs = tf.concat([context_vector, inputs], axis=-1)\n",
        "\n",
        "      if self.cell_type == 'LSTM':\n",
        "        decoder_outputs, state_h, state_c = decoder(inputs, initial_state=states)\n",
        "      if self.cell_type == 'GRU':\n",
        "        decoder_outputs, state_h = decoder(inputs, initial_state=states)\n",
        "      if self.cell_type == 'RNN':\n",
        "        decoder_outputs, state_h = decoder(inputs, initial_state=states)\n",
        "            \n",
        "      outputs = decoder_dense(decoder_outputs)\n",
        "      # Store the current prediction (we will concatenate all predictions later)\n",
        "      outputs = tf.expand_dims(outputs, 1)\n",
        "      all_outputs.append(outputs)\n",
        "      inputs = outputs\n",
        "      if self.cell_type == 'LSTM':\n",
        "        states = [state_h, state_c]\n",
        "      if self.cell_type == 'GRU' or self.cell_type == 'RNN':\n",
        "        states = [state_h]\n",
        "    \n",
        "    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "    seq_outs = decoder_outputs[0]\n",
        "    seq_out = tf.argmax(seq_outs, axis=1)\n",
        "    seq_out = seq_out.numpy()\n",
        "    seq_in = tf.argmax(seq_in, axis = 1)\n",
        "    seq_in = seq_in.numpy()\n",
        "    list(filter(lambda num: num != 0, seq_in))\n",
        "    list(filter(lambda num: num != 0, seq_out))\n",
        "    \n",
        "    return seq_in, seq_out, attention_plot, weigh_atten\n",
        "\n",
        "  def plot_attention(self,attention, sequence, predicted_sequence, idx,fig):\n",
        "    \n",
        "    ax = fig.add_subplot(4, 3, idx)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 16}\n",
        "    seq = ''\n",
        "    for i in range(len(sequence)):\n",
        "      seq = seq + reverse_source_char_index[sequence[i]]\n",
        "    \n",
        "    pred = ''\n",
        "    for i in range(len(predicted_sequence)):\n",
        "      pred = pred + reverse_target_char_index[predicted_sequence[i]]\n",
        "\n",
        "\n",
        "    ax.set_xticklabels(seq, fontdict=fontdict)\n",
        "    ax.set_yticklabels(pred, fontdict=fontdict, fontproperties = tel_font)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    \n",
        "    \n",
        "  def translate(self,seq_in, idx,fig):\n",
        "    seq_in, seq_out, attention_plot, weigh_atten = self.evaluate(seq_in)\n",
        "\n",
        "    a = [0]\n",
        "    for i in range(len(seq_in)):\n",
        "      if seq_in[i] != 0:\n",
        "        a.append(seq_in[i])\n",
        "\n",
        "    b = []\n",
        "    for i in range(len(seq_out)):\n",
        "      if seq_out[i] != 0:\n",
        "        b.append(seq_out[i])\n",
        "  \n",
        "    b = b[:len(b)-1]\n",
        "    #print(a)\n",
        "    #print(b)\n",
        "    \n",
        "    attention_plot = attention_plot[:len(b), :len(a)]\n",
        "    self.plot_attention(attention_plot, a, b, idx,fig)  \n",
        "\n",
        "    return weigh_atten\n",
        "\n",
        "  def attention_plot(self,val_input):\n",
        "    w_a = []\n",
        "    fig = plt.figure(figsize=(16,18))\n",
        "    for i in range(1,13,1): \n",
        "      seq_in = val_input[i*9]\n",
        "      weigh_atten = self.translate(seq_in,i,fig)  \n",
        "      w_a.append(weigh_atten)\n",
        "    plt.show()\n",
        "    return w_a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpH2nJGdCcZ0"
      },
      "source": [
        "## Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6v4kKgONH4q"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes', \n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "\n",
        "        'dropout': {\n",
        "            'values': [0.0, 0.1, 0.2]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-3, 1e-4]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [64, 128]\n",
        "        },\n",
        "        'in_emb': {\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'num_enc': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'num_dec': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'hidden_size':{\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'cell_type': {\n",
        "            'values': ['GRU']\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QeYGKXmlKHr"
      },
      "outputs": [],
      "source": [
        "def train_sweep():\n",
        "  config_defaults = {\n",
        "        'dropout': 0.4,\n",
        "        'learning_rate': 1e-3,\n",
        "        'batch_size': 32,\n",
        "        'epochs' : 10,\n",
        "        'in_emb': 32,\n",
        "        'num_enc': 2,\n",
        "        'num_dec': 2,\n",
        "        'hidden_size': 32,\n",
        "        'cell_type': 'RNN'\n",
        "        }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  wandb.init(config = config_defaults)\n",
        "  \n",
        "  # Config is a variable that holds and saves hyperparameters and inputs\n",
        "  config = wandb.config\n",
        "\n",
        "  wandb.run.name = str(config.cell_type)+ '_' + '_bs_'+str(config.batch_size) + '_hs_'+str(config.hidden_size)\n",
        "  \n",
        "  model_rnn = RNN_Attn(cell_type = config.cell_type, in_emb = config.in_emb, hidden_size=config.hidden_size,\n",
        "                learning_rate= config.learning_rate, dropout=config.dropout,epochs = config.epochs,\n",
        "                batch_size = config.batch_size, num_enc = config.num_enc,num_dec = config.num_dec)\n",
        "  \n",
        "  model_rnn.build(enc_input_data,dec_input_data,dec_target_data,x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHqwHj8ukHYI"
      },
      "outputs": [],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity=\"jyothiraditya\", project=\"assignment3\")\n",
        "wandb.agent(sweep_id, lambda : train_sweep())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "UUkKnyxwMQkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -rf ./TestedAttentionModels/"
      ],
      "metadata": {
        "id": "5QWOwcbfQZnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test"
      ],
      "metadata": {
        "id": "gGq5b7ZKszMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_LSTM = RNN_Attn(cell_type = 'LSTM', in_emb = 64, hidden_size=128, learning_rate= 1e-3,\n",
        "                        dropout=0.2,epochs = 15, batch_size = 128, num_enc = 2,num_dec = 2)"
      ],
      "metadata": {
        "id": "I3aeFbbDs0_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder,attention,decoder,decoder_dense = model_LSTM.build_fit(encoder_input_data,decoder_target_data)"
      ],
      "metadata": {
        "id": "01jtMPvMtMgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_a = model_rnn.attention_plot(val_encoder_input_data[6])"
      ],
      "metadata": {
        "id": "8qqf0RkqtWDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Connectivity"
      ],
      "metadata": {
        "id": "IrfCO9xvtZ5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio imageio -ffmpeg\n",
        "!pip install tqdm\n",
        "\n",
        "import imageio\n",
        "import os   \n",
        "from tqdm import tqdm_notebook as tqdm \n",
        "\n",
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "fRIiMmrGt4jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cstr(s, color='black'):\n",
        "\tif s == ' ':\n",
        "\t\treturn \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
        "\telse:\n",
        "\t\treturn \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
        "\t\n",
        "# print html\n",
        "def print_color(t):\n",
        "\tdisplay(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n",
        "\n",
        "# get appropriate color for value\n",
        "def get_clr(value):\n",
        "\tcolors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n",
        "\t\t'#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "\t\t'#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "\t\t'#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "\tvalue = int((value * 100) / 5)\n",
        "\treturn colors[value]"
      ],
      "metadata": {
        "id": "-WqObifRtbUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng = [16, 21, 20, 8, 20, 8, 1]\n",
        "tel = [25, 40, 22, 48, 22]\n",
        "\n",
        "eng_rev = ''\n",
        "for i in range(len(eng)):\n",
        "  eng_rev = eng_rev + reverse_source_char_index[eng[i]]\n",
        "\n",
        "tel_rev = ''\n",
        "for i in range(len(tam)):\n",
        "  tel_rev = tel_rev + reverse_target_char_index[tel[i]]\n",
        "\n",
        "\n",
        "len_eng = len(eng)\n",
        "len_tel = len(tel)\n",
        "\n",
        "\n",
        "for i in range(len(tel)):\n",
        "  print(reverse_target_char_index[tel[i]])"
      ],
      "metadata": {
        "id": "CUh02Fc_tefN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(output_values, result_list):\n",
        "  #print(\"\\nCell Number:\", cell_no, \"\\n\")\n",
        "  text_colours = []\n",
        "  for i in range(len_eng):\n",
        "    text = (result_list[i], get_clr(output_values[i]))\n",
        "    #text = (result_list, get_clr(output_values))  \n",
        "    text_colours.append(text)\n",
        "    if i == len_eng-1:\n",
        "      print_color(text_colours)"
      ],
      "metadata": {
        "id": "9q0FyxKxtgFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(len_tel):\n",
        "  visualize(w_a[j][:], eng_rev)"
      ],
      "metadata": {
        "id": "ngCcPJj-tiis"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Transliteration_with_attention_FINAL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}