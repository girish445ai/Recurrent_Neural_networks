{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girish445ai/Recurrent_Neural_networks/blob/main/Transliteration_with_attention_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTK4IFUhLr8N"
      },
      "source": [
        "### Importing Libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apeRGrBs6yH8"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import tensorflow \n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, GRU, Dropout, SimpleRNN\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from math import log\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from math import log1p "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NsYPEEpM5cU",
        "outputId": "df7b7a36-cbbb-4d3a-a073-98c2683e1cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 39.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 36.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install wandb -q\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6lJCkKMLwDe"
      },
      "source": [
        "### Unzipping the dataset\n",
        "\n",
        "Lexicons for Latin-Telugu are taken from Google's Dakshina dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhpFjBqec5sk",
        "outputId": "a6a87132-4e2e-4785-f69f-0a369414cc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-07 19:24:56--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.6.128, 142.250.152.128, 142.251.120.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.6.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G  73.0MB/s    in 15s     \n",
            "\n",
            "2022-05-07 19:25:11 (127 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloading dakshina dataset\n",
        "!yes | wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8V3WTrkfF66"
      },
      "outputs": [],
      "source": [
        "# Unzipping dataset\n",
        "!yes | tar xopf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9IlHm7CfO_I",
        "outputId": "b1a2465a-0063-40cf-c0c1-b94f4b6a160e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "te.translit.sampled.dev.tsv   te.translit.sampled.train.tsv\n",
            "te.translit.sampled.test.tsv\n"
          ]
        }
      ],
      "source": [
        "# The folder containing the datasets to be used in this program\n",
        "!ls dakshina_dataset_v1.0/te/lexicons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x95CxiMFl54"
      },
      "outputs": [],
      "source": [
        "print_data = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPoGXywuL1kD"
      },
      "source": [
        "## Reading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBzvL2e20Sx-",
        "outputId": "be3c7c8d-e8b2-4ace-a772-4a3ea7dc49a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  58550\n",
            "Number of validation samples:  5683\n",
            "Number of testing samples:  5683\n"
          ]
        }
      ],
      "source": [
        "train_path = \"./dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv\"\n",
        "dev_path = \"./dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\"\n",
        "test_path = \"./dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\"\n",
        "\n",
        "def reading_data(corpus_file):\n",
        "  # function reads the raw text of words and returns native versions of words\n",
        "  telugu_words = []\n",
        "  latin_words = []\n",
        "  with io.open(corpus_file, encoding ='utf-8') as f:\n",
        "    for line in f:\n",
        "      if '\\t' not in line:\n",
        "        continue\n",
        "      tokens = line.rstrip().split(\"\\t\")\n",
        "      latin_words.append(tokens[1])\n",
        "      telugu_words.append(tokens[0])\n",
        "  return latin_words, telugu_words\n",
        "\n",
        "train_source, train_target = reading_data(train_path)\n",
        "val_source, val_target = reading_data(dev_path)\n",
        "test_source, test_target = reading_data(test_path)\n",
        "\n",
        "print(\"Number of training samples: \", len(train_source))\n",
        "print(\"Number of validation samples: \", len(val_source))\n",
        "print(\"Number of testing samples: \", len(test_source))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mC2ICFKRUZA",
        "outputId": "ef901a6a-82d7-4fb8-db42-d55f0aac9290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 58550\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 25\n",
            "Max sequence length for outputs: 22\n",
            "Max sequence length for val inputs: 21\n",
            "Max sequence length for val outputs: 21\n",
            "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "[' ', 'B', 'E', 'ం', 'ః', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'వ', 'శ', 'ష', 'స', 'హ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్', '\\u200c']\n"
          ]
        }
      ],
      "source": [
        "arr = np.arange(len(train_source))\n",
        "np.random.shuffle(arr)\n",
        "arr1 = np.arange(len(val_source))\n",
        "np.random.shuffle(arr1)\n",
        "\n",
        "input_chars = set()\n",
        "target_chars = set()\n",
        "input_texts_ns = []\n",
        "target_texts_ns = []\n",
        "val_input_texts_ns = []\n",
        "val_target_texts_ns = []\n",
        "\n",
        "for (input_text, target_text) in zip(train_source, train_target):\n",
        "    # \"tab\" is the \"start sequence\" characte ,\"\\n\" is \"end sequence\" character.\n",
        "    target_text = \"B\" + target_text + \"E\"\n",
        "    input_texts_ns.append(input_text)\n",
        "    target_texts_ns.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_chars:\n",
        "            input_chars.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_chars:\n",
        "            target_chars.add(char)\n",
        "\n",
        "for (input_text, target_text) in zip(val_source, val_target):\n",
        "    # \"tab\" is the \"start sequence\" characte ,\"\\n\" is \"end sequence\" character.\n",
        "    target_text = \"B\" + target_text + \"E\"\n",
        "    val_input_texts_ns.append(input_text)\n",
        "    val_target_texts_ns.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_chars:\n",
        "            input_chars.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_chars:\n",
        "            target_chars.add(char)\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "for i in range(len(train_source)):\n",
        "    input_texts.append(input_texts_ns[arr[i]])\n",
        "    target_texts.append(target_texts_ns[arr[i]])\n",
        "\n",
        "val_input_texts = []\n",
        "val_target_texts = []\n",
        "\n",
        "for i in range(len(val_source)):\n",
        "    val_input_texts.append(val_input_texts_ns[arr1[i]])\n",
        "    val_target_texts.append(val_target_texts_ns[arr1[i]])\n",
        "\n",
        "input_chars.add(\" \")\n",
        "target_chars.add(\" \")\n",
        "\n",
        "input_chars = sorted(list(input_chars))\n",
        "target_chars = sorted(list(target_chars))\n",
        "\n",
        "\n",
        "no_enc_tokens = len(input_chars)\n",
        "no_dec_tokens = len(target_chars)\n",
        "enc_seq_length = max([len(txt) for txt in input_texts])\n",
        "dec_seq_length = max([len(txt) for txt in target_texts])\n",
        "val_max_encoder_seq_length = max([len(txt) for txt in val_input_texts])\n",
        "val_max_decoder_seq_length = max([len(txt) for txt in val_target_texts])\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", no_enc_tokens)\n",
        "print(\"Number of unique output tokens:\", no_dec_tokens)\n",
        "print(\"Max sequence length for inputs:\", enc_seq_length)\n",
        "print(\"Max sequence length for outputs:\", dec_seq_length)\n",
        "print(\"Max sequence length for val inputs:\", val_max_encoder_seq_length)\n",
        "print(\"Max sequence length for val outputs:\", val_max_decoder_seq_length)\n",
        "\n",
        "print(input_chars)\n",
        "print(target_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f7y6C51r1QI",
        "outputId": "c7e1da0c-9a63-4c8d-e24a-b1cb17a9d754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['soura', 'pramaadakaramiena', 'cheyistu', 'samvatsaaraalalo', 'naitikataku', 'vaarasulanu', 'droham']\n",
            "['BసౌరE', 'Bప్రమాదకరమైనE', 'Bచేయిస్తూE', 'Bసంవత్సరాలలోE', 'BనైతికతకుE', 'BవారసులనుE', 'Bద్రోహంE']\n"
          ]
        }
      ],
      "source": [
        "print(input_texts[123:130])\n",
        "print(target_texts[123:130])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwPNb93PRwHT"
      },
      "source": [
        "**Training** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtHaPQPw6VuP",
        "outputId": "9f99968a-e821-4926-e1d2-5e3659d2323b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "{' ': 0, 'B': 1, 'E': 2, 'ం': 3, 'ః': 4, 'అ': 5, 'ఆ': 6, 'ఇ': 7, 'ఈ': 8, 'ఉ': 9, 'ఊ': 10, 'ఋ': 11, 'ఎ': 12, 'ఏ': 13, 'ఐ': 14, 'ఒ': 15, 'ఓ': 16, 'ఔ': 17, 'క': 18, 'ఖ': 19, 'గ': 20, 'ఘ': 21, 'చ': 22, 'ఛ': 23, 'జ': 24, 'ఝ': 25, 'ఞ': 26, 'ట': 27, 'ఠ': 28, 'డ': 29, 'ఢ': 30, 'ణ': 31, 'త': 32, 'థ': 33, 'ద': 34, 'ధ': 35, 'న': 36, 'ప': 37, 'ఫ': 38, 'బ': 39, 'భ': 40, 'మ': 41, 'య': 42, 'ర': 43, 'ఱ': 44, 'ల': 45, 'ళ': 46, 'వ': 47, 'శ': 48, 'ష': 49, 'స': 50, 'హ': 51, 'ా': 52, 'ి': 53, 'ీ': 54, 'ు': 55, 'ూ': 56, 'ృ': 57, 'ె': 58, 'ే': 59, 'ై': 60, 'ొ': 61, 'ో': 62, 'ౌ': 63, '్': 64, '\\u200c': 65}\n"
          ]
        }
      ],
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_chars)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_chars)])\n",
        "print(input_token_index)\n",
        "print(target_token_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3i7ykYbtQ2K"
      },
      "outputs": [],
      "source": [
        "# Encoder Input Sequences are padded to a maximum length of MAX encoder SeqLen characters. \n",
        "enc_input_data = np.zeros(\n",
        "    (len(input_texts), enc_seq_length), dtype=\"float32\"\n",
        ")\n",
        "dec_input_data = np.zeros(\n",
        "    (len(input_texts), dec_seq_length), dtype=\"float32\"\n",
        ")\n",
        "dec_target_data = np.zeros(\n",
        "    (len(input_texts), dec_seq_length, no_dec_tokens), dtype=\"float32\"\n",
        ")\n",
        "#Decoder Target Sequences are Padded to a maximum length of max_decoder SeqLen characters with a vocabulary of sizeofTeluguVocab different characters. \n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        enc_input_data[i, t] = input_token_index[char]\n",
        "    enc_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "\n",
        "    for t, char in enumerate(target_text):\n",
        "        # dec_target_data is ahead of dec_input_data by one timestep\n",
        "        dec_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # dec_target_data will not include the start character.\n",
        "            dec_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    dec_input_data[i, t + 1: ] = target_token_index[\" \"]\n",
        "    dec_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "\n",
        "val_enc_input_data = np.zeros(\n",
        "    (len(input_texts), val_max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_dec_input_data = np.zeros(\n",
        "    (len(input_texts), val_max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_dec_target_data = np.zeros(\n",
        "    (len(input_texts), val_max_decoder_seq_length, no_dec_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        val_enc_input_data[i, t] = input_token_index[char]\n",
        "    val_enc_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "\n",
        "    for t, char in enumerate(target_text):\n",
        "        # dec_target_data is ahead of decoder_input_data by one timestep\n",
        "        val_dec_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # dec_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            val_dec_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    val_dec_input_data[i, t + 1: ] = target_token_index[\" \"]\n",
        "    val_dec_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOUdwNGG39qb",
        "outputId": "9e0142a7-4668-474f-d304-9bbb96ae846f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: ' ', 1: 'B', 2: 'E', 3: 'ం', 4: 'ః', 5: 'అ', 6: 'ఆ', 7: 'ఇ', 8: 'ఈ', 9: 'ఉ', 10: 'ఊ', 11: 'ఋ', 12: 'ఎ', 13: 'ఏ', 14: 'ఐ', 15: 'ఒ', 16: 'ఓ', 17: 'ఔ', 18: 'క', 19: 'ఖ', 20: 'గ', 21: 'ఘ', 22: 'చ', 23: 'ఛ', 24: 'జ', 25: 'ఝ', 26: 'ఞ', 27: 'ట', 28: 'ఠ', 29: 'డ', 30: 'ఢ', 31: 'ణ', 32: 'త', 33: 'థ', 34: 'ద', 35: 'ధ', 36: 'న', 37: 'ప', 38: 'ఫ', 39: 'బ', 40: 'భ', 41: 'మ', 42: 'య', 43: 'ర', 44: 'ఱ', 45: 'ల', 46: 'ళ', 47: 'వ', 48: 'శ', 49: 'ష', 50: 'స', 51: 'హ', 52: 'ా', 53: 'ి', 54: 'ీ', 55: 'ు', 56: 'ూ', 57: 'ృ', 58: 'ె', 59: 'ే', 60: 'ై', 61: 'ొ', 62: 'ో', 63: 'ౌ', 64: '్', 65: '\\u200c'}\n"
          ]
        }
      ],
      "source": [
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "print(reverse_target_char_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjskNaet7bgj",
        "outputId": "85da2a18-aaa4-4849-c7ac-b5c8aaae89c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16.  1.  5. 12. 21.  4. 21. 11. 21.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.]\n",
            "[ 1. 37. 59. 45. 55. 29. 55. 18. 55.  2.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(enc_input_data[1])\n",
        "print(dec_input_data[1])\n",
        "print(dec_target_data[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui9pFxRvSdeT"
      },
      "source": [
        "For Validation and testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVGsHbTJn807",
        "outputId": "4dc56f7c-8923-499f-da09-2420b160cddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1. 37. 58. 43. 53. 20. 53. 37. 62. 32. 55. 36. 64. 36.  2.  0.  0.  0.\n",
            "  0.  0.  0.]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(val_dec_input_data[26])\n",
        "print(val_dec_target_data[26])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7q6xNssrRwb"
      },
      "outputs": [],
      "source": [
        "x_test = val_enc_input_data\n",
        "y_test = val_target_texts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(AttentionLayer, self).__init__(units)\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "    \n",
        "  def call(self, query, values):\n",
        "    \n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "    \n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "R9FWgg6-Zk_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape = tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer = 'uniform',\n",
        "                                   trainable = True)\n",
        "\n",
        "        self.U_a = self.add_weight(name = 'U_a',\n",
        "                                   shape = tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer = 'uniform',\n",
        "                                   trainable = True)\n",
        "\n",
        "        self.V_a = self.add_weight(name = 'V_a',\n",
        "                                   shape = tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer = 'uniform',\n",
        "                                   trainable = True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs):\n",
        "       \n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "           \n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "            \n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n"
      ],
      "metadata": {
        "id": "aXgEHRqHSYPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL TRAINING "
      ],
      "metadata": {
        "id": "fsl1l9XK_jm0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvI1fI7UOPMT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MyRNN(object):\n",
        "  def __init__(self,cell_type = 'RNN',in_emb = 32, hidden_size=32, learning_rate= 1e-3, \n",
        "               dropout=0.4,epochs = 10, batch_size = 32,\n",
        "               num_enc = 1,num_dec = 1):\n",
        "    \n",
        "    self.cell_type = cell_type\n",
        "    self.in_emb = in_emb\n",
        "    self.hidden_size = hidden_size\n",
        "    self.learning_rate = learning_rate\n",
        "    self.dropout = dropout\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.num_enc = num_enc\n",
        "    self.num_dec = num_dec\n",
        "\n",
        "  def build_fit(self,enc_input_data,dec_input_data,dec_target_data,x_test, y_test):\n",
        "    enc_inputs = Input(shape=(None, ),name = 'Enc_inputs')\n",
        "\n",
        "    # Add an Embedding layer expecting input vocab of size no_enc_tokens, and\n",
        "    # output embedding dimension of size in_enc.\n",
        "    enc_emb =  Embedding(no_enc_tokens, self.in_emb , mask_zero = True,name = 'Enc_emb')(enc_inputs)\n",
        "\n",
        "    enc_outputs = enc_emb\n",
        "    if self.cell_type == 'LSTM':\n",
        "      encoder_lstm = LSTM(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "      enc_outputs, state_h, state_c = encoder_lstm(enc_outputs)\n",
        "      encoder_states = [state_h, state_c]\n",
        "      encoder_first_outputs = enc_outputs\n",
        "\n",
        "      # Add a LSTM layer with hidden_size internal units.\n",
        "      for i in range( 2, self.num_enc +1):\n",
        "        layer_name = ('Enc_hidden_%d') %i\n",
        "        encoder_lstm = LSTM(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "        enc_outputs, state_h, state_c = encoder_lstm(enc_outputs,initial_state = encoder_states)\n",
        "        encoder_states = [state_h, state_c]\n",
        "\n",
        "    elif self.cell_type == 'GRU':\n",
        "      encoder_gru = GRU(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "      enc_outputs, state_h = encoder_gru(enc_outputs)\n",
        "      encoder_states = [state_h]\n",
        "      encoder_first_outputs = enc_outputs\n",
        "\n",
        "      for i in range(2, self.num_enc +1):\n",
        "        layer_name = ('Enc_hidden_%d') %i\n",
        "        encoder_gru = GRU(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "        enc_outputs, state_h = encoder_gru(enc_outputs, initial_state = encoder_states)\n",
        "        encoder_states = [state_h]  \n",
        "\n",
        "    elif self.cell_type == 'RNN':\n",
        "      encoder_rnn = SimpleRNN(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "      enc_outputs, state_h = encoder_rnn(enc_outputs)\n",
        "      encoder_states = [state_h]\n",
        "      encoder_first_outputs = enc_outputs\n",
        "\n",
        "      for i in range(2, self.num_enc +1):\n",
        "        layer_name = ('Enc_hidden_%d') %i\n",
        "        encoder_rnn = SimpleRNN(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "        enc_outputs, state_h = encoder_rnn(enc_outputs, initial_state = encoder_states)\n",
        "        encoder_states = [state_h]  \n",
        "\n",
        "    # Set up the decoder, using `encoder_states` as initial state.\n",
        "    dec_inputs = Input(shape=(None,), name = 'Dec_inputs')\n",
        "    dec_emb_layer = Embedding(no_dec_tokens, self.hidden_size, mask_zero = True, name = 'Dec_emb')\n",
        "    dec_emb = dec_emb_layer(dec_inputs)\n",
        "    # We set up our decoder to return full output sequences,\n",
        "    # and to return internal states as well. We don't use the\n",
        "    # return states in the training model, but we will use them in inference.\n",
        "    dec_outputs = dec_emb\n",
        "    decoder_first_outputs = dec_outputs\n",
        "    if self.cell_type == 'LSTM':\n",
        "      decoder_lstm = LSTM(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "      dec_outputs, _, _ = decoder_lstm(dec_outputs, initial_state = encoder_states)\n",
        "      \n",
        "      for i in range(2, self.num_dec +1):\n",
        "        layer_name = ('Dec_hidden_%d') %i\n",
        "        decoder_lstm = LSTM(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "        dec_outputs, _, _ = decoder_lstm(dec_outputs, initial_state = encoder_states)\n",
        "        if i == self.num_dec:\n",
        "          decoder_first_outputs = dec_outputs\n",
        "\n",
        "    elif self.cell_type == 'GRU':\n",
        "      decoder_gru = GRU(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "      dec_outputs, _ = decoder_gru(dec_outputs, initial_state = encoder_states)\n",
        "\n",
        "      for i in range(2, self.num_dec+1):\n",
        "        layer_name = ('Dec_hidden_%d') %i\n",
        "        decoder_gru = GRU(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "        dec_outputs, _ = decoder_gru(dec_outputs, initial_state = encoder_states)\n",
        "        if i == self.num_dec:\n",
        "          decoder_first_outputs = dec_outputs\n",
        "\n",
        "    elif self.cell_type == 'RNN':\n",
        "      decoder_rnn = SimpleRNN(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "      dec_outputs, _ = decoder_rnn(dec_outputs, initial_state = encoder_states)\n",
        "\n",
        "      for i in range(2, self.num_dec+1):\n",
        "        layer_name = ('Dec_hidden_%d') %i\n",
        "        decoder_rnn = SimpleRNN(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "        dec_outputs, _ = decoder_rnn(dec_outputs, initial_state = encoder_states)\n",
        "        if i == self.num_dec:\n",
        "          decoder_first_outputs = dec_outputs\n",
        "\n",
        "    attention_layer = AttentionLayer(name='attention_layer')\n",
        "    attention_out, attention_states = attention_layer([enc_outputs, dec_outputs])\n",
        "\n",
        "    decoder_concat_input = keras.layers.Concatenate(axis=-1, name='concat_layer')([dec_outputs, attention_out])\n",
        "\n",
        "    decoder_dense = Dense(no_dec_tokens, activation='softmax', name = 'dense')\n",
        "    dec_outputs = decoder_dense(dec_outputs)\n",
        "\n",
        "    # Define the model that takes encoder and decoder input \n",
        "    # to output dec_outputs\n",
        "    model = Model([enc_inputs, dec_inputs], dec_outputs)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy'])\n",
        "  \n",
        "    model.fit(\n",
        "        [enc_input_data, dec_input_data],\n",
        "        dec_target_data,\n",
        "        batch_size=self.batch_size,\n",
        "        epochs=self.epochs,\n",
        "        callbacks = [WandbCallback()]\n",
        "        )\n",
        "    \n",
        "    pred=model.predict(val_enc_input_data[:5500], batch_size=self.batch_size)\n",
        "\n",
        "    global_count = 0\n",
        "    count = 0\n",
        "    global_total = 0\n",
        "    global_correct = 0\n",
        "    val_total = 5500\n",
        "    for index in range(0, val_total):\n",
        "      one_hot_vector = pred[index]\n",
        "      one_hot_vector1 = val_dec_target_data[index]\n",
        "      index2 = tf.argmax(one_hot_vector, axis=1)\n",
        "      index1 = tf.argmax(one_hot_vector1, axis=1)\n",
        "      #a = (index2-index1).numpy()\n",
        "      if (index2.numpy() == index1.numpy()).all():\n",
        "        global_correct = global_correct + 1\n",
        "        \n",
        "      global_total = global_total + 1\n",
        "      accuracy_epoch = global_correct/global_total\n",
        "      if global_total % 50 == 0:\n",
        "        wandb.log({'epoch_accuracy' : accuracy_epoch})\n",
        "      #print(\"Accuracy: %s\" % (accuracy_epoch))\n",
        "    \n",
        "    val_accuracy = global_correct/global_total\n",
        "    #print(val_accuracy)\n",
        "\n",
        "    wandb.log({'val_accuracy' : val_accuracy})\n",
        "\n",
        "    if self.cell_type == 'LSTM':\n",
        "      return encoder_lstm,attention_layer,decoder_lstm,decoder_dense\n",
        "    if self.cell_type == 'GRU':\n",
        "      return encoder_gru,attention_layer,decoder_gru,decoder_dense\n",
        "    if self.cell_type == 'RNN':\n",
        "      return encoder_rnn,attention_layer,decoder_rnn,decoder_dense  \n",
        "\n",
        "  def evaluate(self,seq_in):\n",
        "    attention_plot = np.zeros((max_decoder_seq_length, max_encoder_seq_length))\n",
        "    #sequence = [7, 9, 8, 5]\n",
        "    sequence = seq_in\n",
        "    #sequence = one_hot_encode(seq_in,num_encoder_tokens)\n",
        "    encoder_inputs=array(sequence).reshape(1,max_encoder_seq_length,num_encoder_tokens)\n",
        "    \n",
        "    encoder_inputs = tf.convert_to_tensor(encoder_inputs,dtype=tf.float32)\n",
        "    \n",
        "    if self.cell_type == 'LSTM':\n",
        "      #encoder_lstm = LSTM(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_lstm')\n",
        "      encoder_outputs, encoder_state_h, encoder_state_c = encoder(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h, encoder_state_c]\n",
        "    elif self.cell_type == 'GRU':\n",
        "      #encoder_gru = GRU(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_gru')\n",
        "      encoder_outputs, encoder_state_h = encoder(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h]\n",
        "    elif self.cell_type == 'RNN':\n",
        "      #encoder_rnn = SimpleRNN(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_rnn')\n",
        "      encoder_outputs, encoder_state_h = encoder(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h]\n",
        "\n",
        "    all_outputs = []\n",
        "\n",
        "    decoder_input_data = np.zeros((1, 1, num_decoder_tokens))\n",
        "    decoder_input_data[:, 0, 0] = 1 \n",
        "\n",
        "    inputs = decoder_input_data\n",
        "    decoder_outputs = encoder_state_h\n",
        "    states = encoder_states\n",
        "\n",
        "    weigh_atten =[]\n",
        "    for t in range(max_decoder_seq_length):\n",
        "\n",
        "      # pay attention\n",
        "      context_vector, attention_weights=attention(decoder_outputs, encoder_outputs)\n",
        "\n",
        "      # storing the attention weights to plot later on\n",
        "      attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "      weigh_atten.append(attention_weights)\n",
        "      \n",
        "      attention_plot[t] = attention_weights.numpy()\n",
        "      \n",
        "      decoder_outputs=tf.expand_dims(decoder_outputs, 1)\n",
        "\n",
        "      context_vector = tf.expand_dims(context_vector, 1)\n",
        "      inputs = tf.concat([context_vector, inputs], axis=-1)\n",
        "\n",
        "      if self.cell_type == 'LSTM':\n",
        "        decoder_outputs, state_h, state_c = decoder(inputs, initial_state=states)\n",
        "      if self.cell_type == 'GRU':\n",
        "        decoder_outputs, state_h = decoder(inputs, initial_state=states)\n",
        "      if self.cell_type == 'RNN':\n",
        "        decoder_outputs, state_h = decoder(inputs, initial_state=states)\n",
        "            \n",
        "      outputs = decoder_dense(decoder_outputs)\n",
        "      # Store the current prediction (we will concatenate all predictions later)\n",
        "      outputs = tf.expand_dims(outputs, 1)\n",
        "      all_outputs.append(outputs)\n",
        "      inputs = outputs\n",
        "      if self.cell_type == 'LSTM':\n",
        "        states = [state_h, state_c]\n",
        "      if self.cell_type == 'GRU' or self.cell_type == 'RNN':\n",
        "        states = [state_h]\n",
        "    \n",
        "    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "    seq_outs = decoder_outputs[0]\n",
        "    seq_out = tf.argmax(seq_outs, axis=1)\n",
        "    seq_out = seq_out.numpy()\n",
        "    seq_in = tf.argmax(seq_in, axis = 1)\n",
        "    seq_in = seq_in.numpy()\n",
        "    list(filter(lambda num: num != 0, seq_in))\n",
        "    list(filter(lambda num: num != 0, seq_out))\n",
        "    \n",
        "    return seq_in, seq_out, attention_plot, weigh_atten\n",
        "\n",
        "  def plot_attention(self,attention, sequence, predicted_sequence, idx,fig):\n",
        "    \n",
        "    ax = fig.add_subplot(4, 3, idx)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 16}\n",
        "    seq = ''\n",
        "    for i in range(len(sequence)):\n",
        "      seq = seq + reverse_source_char_index[sequence[i]]\n",
        "    \n",
        "    pred = ''\n",
        "    for i in range(len(predicted_sequence)):\n",
        "      pred = pred + reverse_target_char_index[predicted_sequence[i]]\n",
        "\n",
        "    #ax.rcParams[\"font.family\"] = \"Vijaya\"\n",
        "    ax.set_xticklabels(seq, fontdict=fontdict)\n",
        "    ax.set_yticklabels(pred, fontdict=fontdict, fontproperties = tamil_font)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    \n",
        "    \n",
        "  def translate(self,seq_in, idx,fig):\n",
        "    seq_in, seq_out, attention_plot, weigh_atten = self.evaluate(seq_in)\n",
        "\n",
        "    a = [0]\n",
        "    for i in range(len(seq_in)):\n",
        "      if seq_in[i] != 0:\n",
        "        a.append(seq_in[i])\n",
        "\n",
        "    b = []\n",
        "    for i in range(len(seq_out)):\n",
        "      if seq_out[i] != 0:\n",
        "        b.append(seq_out[i])\n",
        "  \n",
        "    b = b[:len(b)-1]\n",
        "    #print(a)\n",
        "    #print(b)\n",
        "    \n",
        "    attention_plot = attention_plot[:len(b), :len(a)]\n",
        "    self.plot_attention(attention_plot, a, b, idx,fig)  \n",
        "\n",
        "    return weigh_atten\n",
        "\n",
        "  def attention_plot(self,val_input):\n",
        "    w_a = []\n",
        "    fig = plt.figure(figsize=(16,18))\n",
        "    for i in range(1,13,1): \n",
        "      seq_in = val_input[i*9]\n",
        "      weigh_atten = self.translate(seq_in,i,fig)  \n",
        "      w_a.append(weigh_atten)\n",
        "    plt.show()\n",
        "    return w_a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpH2nJGdCcZ0"
      },
      "source": [
        "## Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6v4kKgONH4q"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes', \n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "\n",
        "        'dropout': {\n",
        "            'values': [0.0, 0.1, 0.2]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-3, 1e-4]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [64, 128]\n",
        "        },\n",
        "        'in_emb': {\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'num_enc': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'num_dec': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'hidden_size':{\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'cell_type': {\n",
        "            'values': ['GRU']\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QeYGKXmlKHr"
      },
      "outputs": [],
      "source": [
        "def train_sweep():\n",
        "  config_defaults = {\n",
        "        'dropout': 0.4,\n",
        "        'learning_rate': 1e-3,\n",
        "        'batch_size': 32,\n",
        "        'epochs' : 10,\n",
        "        'in_emb': 32,\n",
        "        'num_enc': 2,\n",
        "        'num_dec': 2,\n",
        "        'hidden_size': 32,\n",
        "        'cell_type': 'RNN'\n",
        "        }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  wandb.init(config = config_defaults)\n",
        "  \n",
        "  # Config is a variable that holds and saves hyperparameters and inputs\n",
        "  config = wandb.config\n",
        "\n",
        "  wandb.run.name = str(config.cell_type)+ '_' + '_bs_'+str(config.batch_size) + '_hs_'+str(config.hidden_size)\n",
        "  \n",
        "  model_rnn = MyRNN(cell_type = config.cell_type, in_emb = config.in_emb, hidden_size=config.hidden_size,\n",
        "                learning_rate= config.learning_rate, dropout=config.dropout,epochs = config.epochs,\n",
        "                batch_size = config.batch_size, num_enc = config.num_enc,num_dec = config.num_dec)\n",
        "  \n",
        "  model_rnn.build_fit(enc_input_data,dec_input_data,dec_target_data,x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f43a15f176f47d1a9c7f2e9219a3552",
            "5eaa34627e1d4f708979e8d4d060a85e",
            "3d08ed66de224180b211887b4141d23f",
            "de750eac55d148878a84c868f6b86a5b",
            "851d32d7c77b4edb8bb57147afa411a1",
            "e78feecb4b4349609d0c5ad29d1f801e",
            "9f998629c8114ceb9cd47ce804f61672",
            "f85c5290c56a40618697d41df4f0bbdb"
          ]
        },
        "id": "AHqwHj8ukHYI",
        "outputId": "81d64168-f189-470a-8a80-6c52ca2e3911"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: kuatwm7t\n",
            "Sweep URL: https://wandb.ai/jyothiraditya/assignment3/sweeps/kuatwm7t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s4myjtcz with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_emb: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjyothiraditya\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220507_192552-s4myjtcz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jyothiraditya/assignment3/runs/s4myjtcz\" target=\"_blank\">twilight-sweep-1</a></strong> to <a href=\"https://wandb.ai/jyothiraditya/assignment3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/jyothiraditya/assignment3/sweeps/kuatwm7t\" target=\"_blank\">https://wandb.ai/jyothiraditya/assignment3/sweeps/kuatwm7t</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Enc_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_emb (Embedding)            (None, None, 128)    3456        ['Enc_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_hidden_1 (LSTM)            [(None, None, 64),   49408       ['Enc_emb[0][0]']                \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " Dec_emb (Embedding)            (None, None, 64)     4224        ['Dec_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Enc_hidden_2 (LSTM)            [(None, None, 64),   33024       ['Enc_hidden_1[0][0]',           \n",
            "                                 (None, 64),                      'Enc_hidden_1[0][1]',           \n",
            "                                 (None, 64)]                      'Enc_hidden_1[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_1 (LSTM)            [(None, None, 64),   33024       ['Dec_emb[0][0]',                \n",
            "                                 (None, 64),                      'Enc_hidden_2[0][1]',           \n",
            "                                 (None, 64)]                      'Enc_hidden_2[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_2 (LSTM)            [(None, None, 64),   33024       ['Dec_hidden_1[0][0]',           \n",
            "                                 (None, 64),                      'Enc_hidden_2[0][1]',           \n",
            "                                 (None, 64)]                      'Enc_hidden_2[0][2]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     4290        ['Dec_hidden_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 160,450\n",
            "Trainable params: 160,450\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "458/458 [==============================] - 45s 51ms/step - loss: 1.1814 - accuracy: 0.3014 - _timestamp: 1651951611.0000 - _runtime: 59.0000\n",
            "Epoch 2/10\n",
            "458/458 [==============================] - 22s 48ms/step - loss: 0.7650 - accuracy: 0.5319 - _timestamp: 1651951633.0000 - _runtime: 81.0000\n",
            "Epoch 3/10\n",
            "458/458 [==============================] - 22s 49ms/step - loss: 0.5084 - accuracy: 0.6801 - _timestamp: 1651951655.0000 - _runtime: 103.0000\n",
            "Epoch 4/10\n",
            "458/458 [==============================] - 22s 49ms/step - loss: 0.3701 - accuracy: 0.7626 - _timestamp: 1651951678.0000 - _runtime: 126.0000\n",
            "Epoch 5/10\n",
            "458/458 [==============================] - 22s 49ms/step - loss: 0.2992 - accuracy: 0.8057 - _timestamp: 1651951700.0000 - _runtime: 148.0000\n",
            "Epoch 6/10\n",
            "458/458 [==============================] - 22s 49ms/step - loss: 0.2541 - accuracy: 0.8341 - _timestamp: 1651951722.0000 - _runtime: 170.0000\n",
            "Epoch 7/10\n",
            "458/458 [==============================] - 22s 49ms/step - loss: 0.2235 - accuracy: 0.8533 - _timestamp: 1651951744.0000 - _runtime: 192.0000\n",
            "Epoch 8/10\n",
            "458/458 [==============================] - 22s 49ms/step - loss: 0.2016 - accuracy: 0.8679 - _timestamp: 1651951767.0000 - _runtime: 215.0000\n",
            "Epoch 9/10\n",
            "458/458 [==============================] - 22s 48ms/step - loss: 0.1841 - accuracy: 0.8795 - _timestamp: 1651951789.0000 - _runtime: 237.0000\n",
            "Epoch 10/10\n",
            "458/458 [==============================] - 22s 48ms/step - loss: 0.1696 - accuracy: 0.8891 - _timestamp: 1651951811.0000 - _runtime: 259.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f43a15f176f47d1a9c7f2e9219a3552"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▆▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.88906</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.16955</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">twilight-sweep-1</strong>: <a href=\"https://wandb.ai/jyothiraditya/assignment3/runs/s4myjtcz\" target=\"_blank\">https://wandb.ai/jyothiraditya/assignment3/runs/s4myjtcz</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220507_192552-s4myjtcz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Run s4myjtcz errored: ValueError('in user code:\\n\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\\n        return step_function(self, iterator)\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\\n        outputs = model.predict_step(data)\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\\n        return self(x, training=False)\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\\n        raise e.with_traceback(filtered_tb) from None\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\\n        raise ValueError(f\\'Layer \"{layer_name}\" expects {len(input_spec)} input(s),\\'\\n\\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor \\'IteratorGetNext:0\\' shape=(None, 21) dtype=float32>]\\n')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run s4myjtcz errored: ValueError('in user code:\\n\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\\n        return step_function(self, iterator)\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\\n        outputs = model.predict_step(data)\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\\n        return self(x, training=False)\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\\n        raise e.with_traceback(filtered_tb) from None\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\\n        raise ValueError(f\\'Layer \"{layer_name}\" expects {len(input_spec)} input(s),\\'\\n\\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor \\'IteratorGetNext:0\\' shape=(None, 21) dtype=float32>]\\n')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 25p6gyft with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_emb: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220507_193059-25p6gyft</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jyothiraditya/assignment3/runs/25p6gyft\" target=\"_blank\">sleek-sweep-2</a></strong> to <a href=\"https://wandb.ai/jyothiraditya/assignment3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/jyothiraditya/assignment3/sweeps/kuatwm7t\" target=\"_blank\">https://wandb.ai/jyothiraditya/assignment3/sweeps/kuatwm7t</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Enc_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_emb (Embedding)            (None, None, 64)     1728        ['Enc_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Enc_hidden_1 (SimpleRNN)       [(None, None, 128),  24704       ['Enc_emb[0][0]']                \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " Dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_hidden_2 (SimpleRNN)       [(None, None, 128),  32896       ['Enc_hidden_1[0][0]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_1[0][1]']           \n",
            "                                                                                                  \n",
            " Dec_emb (Embedding)            (None, None, 128)    8448        ['Dec_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Enc_hidden_3 (SimpleRNN)       [(None, None, 128),  32896       ['Enc_hidden_2[0][0]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_2[0][1]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_1 (SimpleRNN)       [(None, None, 128),  32896       ['Dec_emb[0][0]',                \n",
            "                                 (None, 128)]                     'Enc_hidden_3[0][1]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_2 (SimpleRNN)       [(None, None, 128),  32896       ['Dec_hidden_1[0][0]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_3[0][1]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_3 (SimpleRNN)       [(None, None, 128),  32896       ['Dec_hidden_2[0][0]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_3[0][1]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     8514        ['Dec_hidden_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 207,874\n",
            "Trainable params: 207,874\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "458/458 [==============================] - 212s 445ms/step - loss: 1.3554 - accuracy: 0.2285 - _timestamp: 1651952076.0000 - _runtime: 217.0000\n",
            "Epoch 2/10\n",
            "458/458 [==============================] - 203s 443ms/step - loss: 1.0872 - accuracy: 0.3409 - _timestamp: 1651952279.0000 - _runtime: 420.0000\n",
            "Epoch 3/10\n",
            "458/458 [==============================] - 203s 443ms/step - loss: 0.9934 - accuracy: 0.3921 - _timestamp: 1651952482.0000 - _runtime: 623.0000\n",
            "Epoch 4/10\n",
            " 56/458 [==>...........................] - ETA: 3:00 - loss: 0.9491 - accuracy: 0.4188"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity=\"jyothiraditya\", project=\"assignment3\")\n",
        "wandb.agent(sweep_id, lambda : train_sweep())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UUkKnyxwMQkh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Transliteration_with_attention_FINAL.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f43a15f176f47d1a9c7f2e9219a3552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5eaa34627e1d4f708979e8d4d060a85e",
              "IPY_MODEL_3d08ed66de224180b211887b4141d23f"
            ],
            "layout": "IPY_MODEL_de750eac55d148878a84c868f6b86a5b"
          }
        },
        "5eaa34627e1d4f708979e8d4d060a85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_851d32d7c77b4edb8bb57147afa411a1",
            "placeholder": "​",
            "style": "IPY_MODEL_e78feecb4b4349609d0c5ad29d1f801e",
            "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "3d08ed66de224180b211887b4141d23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f998629c8114ceb9cd47ce804f61672",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f85c5290c56a40618697d41df4f0bbdb",
            "value": 1
          }
        },
        "de750eac55d148878a84c868f6b86a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851d32d7c77b4edb8bb57147afa411a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e78feecb4b4349609d0c5ad29d1f801e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f998629c8114ceb9cd47ce804f61672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f85c5290c56a40618697d41df4f0bbdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}