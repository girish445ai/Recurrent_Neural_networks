{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girish445ai/Recurrent_Neural_networks/blob/main/Transliteration_without_attention_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTK4IFUhLr8N"
      },
      "source": [
        "### Importing Libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "apeRGrBs6yH8"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import tensorflow \n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, GRU, Dropout, SimpleRNN\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from math import log\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from math import log1p "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NsYPEEpM5cU",
        "outputId": "d1573ae9-2a7c-4faa-8de8-7faeba313511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 49.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 51.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install wandb -q\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6lJCkKMLwDe"
      },
      "source": [
        "### Unzipping the dataset\n",
        "\n",
        "Lexicons for Latin-Telugu are taken from Google's Dakshina dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhpFjBqec5sk",
        "outputId": "a31356fa-3965-4565-c354-254005414718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-05 09:03:21--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.159.128, 74.125.126.128, 74.125.70.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.159.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   131MB/s    in 11s     \n",
            "\n",
            "2022-05-05 09:03:32 (171 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloading dakshina dataset\n",
        "!yes | wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A8V3WTrkfF66"
      },
      "outputs": [],
      "source": [
        "# Unzipping dataset\n",
        "!yes | tar xopf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9IlHm7CfO_I",
        "outputId": "fd93f030-f748-4f79-d5b8-b6ba50396ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "te.translit.sampled.dev.tsv   te.translit.sampled.train.tsv\n",
            "te.translit.sampled.test.tsv\n"
          ]
        }
      ],
      "source": [
        "# The folder containing the datasets to be used in this program\n",
        "!ls dakshina_dataset_v1.0/te/lexicons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6x95CxiMFl54"
      },
      "outputs": [],
      "source": [
        "print_data = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPoGXywuL1kD"
      },
      "source": [
        "## Reading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBzvL2e20Sx-",
        "outputId": "1041bd88-45b3-4971-de9b-05b33142e32a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  58550\n",
            "Number of validation samples:  5683\n",
            "Number of testing samples:  5683\n"
          ]
        }
      ],
      "source": [
        "train_path = \"./dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv\"\n",
        "dev_path = \"./dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\"\n",
        "test_path = \"./dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\"\n",
        "\n",
        "def reading_data(corpus_file):\n",
        "  # function reads the raw text of words and returns native versions of words\n",
        "  telugu_words = []\n",
        "  latin_words = []\n",
        "  with io.open(corpus_file, encoding ='utf-8') as f:\n",
        "    for line in f:\n",
        "      if '\\t' not in line:\n",
        "        continue\n",
        "      tokens = line.rstrip().split(\"\\t\")\n",
        "      latin_words.append(tokens[1])\n",
        "      telugu_words.append(tokens[0])\n",
        "  return latin_words, telugu_words\n",
        "\n",
        "train_source, train_target = reading_data(train_path)\n",
        "val_source, val_target = reading_data(dev_path)\n",
        "test_source, test_target = reading_data(test_path)\n",
        "\n",
        "print(\"Number of training samples: \", len(train_source))\n",
        "print(\"Number of validation samples: \", len(val_source))\n",
        "print(\"Number of testing samples: \", len(test_source))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mC2ICFKRUZA",
        "outputId": "5364888a-4be1-45e9-cf74-cd7dce86f5a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 58550\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 25\n",
            "Max sequence length for outputs: 22\n",
            "Max sequence length for val inputs: 21\n",
            "Max sequence length for val outputs: 21\n",
            "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "[' ', 'B', 'E', 'ం', 'ః', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'వ', 'శ', 'ష', 'స', 'హ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్', '\\u200c']\n"
          ]
        }
      ],
      "source": [
        "arr = np.arange(len(train_source))\n",
        "np.random.shuffle(arr)\n",
        "arr1 = np.arange(len(val_source))\n",
        "np.random.shuffle(arr1)\n",
        "\n",
        "input_chars = set()\n",
        "target_chars = set()\n",
        "input_texts_ns = []\n",
        "target_texts_ns = []\n",
        "val_input_texts_ns = []\n",
        "val_target_texts_ns = []\n",
        "\n",
        "for (input_text, target_text) in zip(train_source, train_target):\n",
        "    # \"tab\" is the \"start sequence\" characte ,\"\\n\" is \"end sequence\" character.\n",
        "    target_text = \"B\" + target_text + \"E\"\n",
        "    input_texts_ns.append(input_text)\n",
        "    target_texts_ns.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_chars:\n",
        "            input_chars.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_chars:\n",
        "            target_chars.add(char)\n",
        "\n",
        "for (input_text, target_text) in zip(val_source, val_target):\n",
        "    # \"tab\" is the \"start sequence\" characte ,\"\\n\" is \"end sequence\" character.\n",
        "    target_text = \"B\" + target_text + \"E\"\n",
        "    val_input_texts_ns.append(input_text)\n",
        "    val_target_texts_ns.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_chars:\n",
        "            input_chars.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_chars:\n",
        "            target_chars.add(char)\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "for i in range(len(train_source)):\n",
        "    input_texts.append(input_texts_ns[arr[i]])\n",
        "    target_texts.append(target_texts_ns[arr[i]])\n",
        "\n",
        "val_input_texts = []\n",
        "val_target_texts = []\n",
        "\n",
        "for i in range(len(val_source)):\n",
        "    val_input_texts.append(val_input_texts_ns[arr1[i]])\n",
        "    val_target_texts.append(val_target_texts_ns[arr1[i]])\n",
        "\n",
        "input_chars.add(\" \")\n",
        "target_chars.add(\" \")\n",
        "\n",
        "input_chars = sorted(list(input_chars))\n",
        "target_chars = sorted(list(target_chars))\n",
        "\n",
        "\n",
        "no_enc_tokens = len(input_chars)\n",
        "no_dec_tokens = len(target_chars)\n",
        "enc_seq_length = max([len(txt) for txt in input_texts])\n",
        "dec_seq_length = max([len(txt) for txt in target_texts])\n",
        "val_max_encoder_seq_length = max([len(txt) for txt in val_input_texts])\n",
        "val_max_decoder_seq_length = max([len(txt) for txt in val_target_texts])\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", no_enc_tokens)\n",
        "print(\"Number of unique output tokens:\", no_dec_tokens)\n",
        "print(\"Max sequence length for inputs:\", enc_seq_length)\n",
        "print(\"Max sequence length for outputs:\", dec_seq_length)\n",
        "print(\"Max sequence length for val inputs:\", val_max_encoder_seq_length)\n",
        "print(\"Max sequence length for val outputs:\", val_max_decoder_seq_length)\n",
        "\n",
        "print(input_chars)\n",
        "print(target_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f7y6C51r1QI",
        "outputId": "14553122-a477-49e4-d0dd-a9c8d7a06624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['chesukoka', 'gurthincha', 'haindava', 'adugupettina', 'massachusetts', 'untundane', 'paalaace']\n",
            "['BచేసుకోకE', 'Bగుర్తించE', 'BహైందవE', 'Bఅడుగుపెట్టినE', 'Bమసాచుసెట్స్E', 'BఉంటుందనేE', 'Bప్యాలెస్E']\n"
          ]
        }
      ],
      "source": [
        "print(input_texts[123:130])\n",
        "print(target_texts[123:130])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwPNb93PRwHT"
      },
      "source": [
        "**Training** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtHaPQPw6VuP",
        "outputId": "8b01a46b-4dbe-4277-f3de-7321f8506d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "{' ': 0, 'B': 1, 'E': 2, 'ం': 3, 'ః': 4, 'అ': 5, 'ఆ': 6, 'ఇ': 7, 'ఈ': 8, 'ఉ': 9, 'ఊ': 10, 'ఋ': 11, 'ఎ': 12, 'ఏ': 13, 'ఐ': 14, 'ఒ': 15, 'ఓ': 16, 'ఔ': 17, 'క': 18, 'ఖ': 19, 'గ': 20, 'ఘ': 21, 'చ': 22, 'ఛ': 23, 'జ': 24, 'ఝ': 25, 'ఞ': 26, 'ట': 27, 'ఠ': 28, 'డ': 29, 'ఢ': 30, 'ణ': 31, 'త': 32, 'థ': 33, 'ద': 34, 'ధ': 35, 'న': 36, 'ప': 37, 'ఫ': 38, 'బ': 39, 'భ': 40, 'మ': 41, 'య': 42, 'ర': 43, 'ఱ': 44, 'ల': 45, 'ళ': 46, 'వ': 47, 'శ': 48, 'ష': 49, 'స': 50, 'హ': 51, 'ా': 52, 'ి': 53, 'ీ': 54, 'ు': 55, 'ూ': 56, 'ృ': 57, 'ె': 58, 'ే': 59, 'ై': 60, 'ొ': 61, 'ో': 62, 'ౌ': 63, '్': 64, '\\u200c': 65}\n"
          ]
        }
      ],
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_chars)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_chars)])\n",
        "print(input_token_index)\n",
        "print(target_token_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y3i7ykYbtQ2K"
      },
      "outputs": [],
      "source": [
        "# Encoder Input Sequences are padded to a maximum length of MAX encoder SeqLen characters. \n",
        "enc_input_data = np.zeros(\n",
        "    (len(input_texts), enc_seq_length), dtype=\"float32\"\n",
        ")\n",
        "dec_input_data = np.zeros(\n",
        "    (len(input_texts), dec_seq_length), dtype=\"float32\"\n",
        ")\n",
        "dec_target_data = np.zeros(\n",
        "    (len(input_texts), dec_seq_length, no_dec_tokens), dtype=\"float32\"\n",
        ")\n",
        "#Decoder Target Sequences are Padded to a maximum length of max_decoder SeqLen characters with a vocabulary of sizeofTeluguVocab different characters. \n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        enc_input_data[i, t] = input_token_index[char]\n",
        "    enc_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "\n",
        "    for t, char in enumerate(target_text):\n",
        "        # dec_target_data is ahead of dec_input_data by one timestep\n",
        "        dec_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # dec_target_data will not include the start character.\n",
        "            dec_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    dec_input_data[i, t + 1: ] = target_token_index[\" \"]\n",
        "    dec_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "\n",
        "val_enc_input_data = np.zeros(\n",
        "    (len(input_texts), val_max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_dec_input_data = np.zeros(\n",
        "    (len(input_texts), val_max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_dec_target_data = np.zeros(\n",
        "    (len(input_texts), val_max_decoder_seq_length, no_dec_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        val_enc_input_data[i, t] = input_token_index[char]\n",
        "    val_enc_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "\n",
        "    for t, char in enumerate(target_text):\n",
        "        # dec_target_data is ahead of decoder_input_data by one timestep\n",
        "        val_dec_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # dec_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            val_dec_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    val_dec_input_data[i, t + 1: ] = target_token_index[\" \"]\n",
        "    val_dec_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOUdwNGG39qb",
        "outputId": "6dc5ddf3-4da1-4c87-943e-e26f0cbf98e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: ' ', 1: 'B', 2: 'E', 3: 'ం', 4: 'ః', 5: 'అ', 6: 'ఆ', 7: 'ఇ', 8: 'ఈ', 9: 'ఉ', 10: 'ఊ', 11: 'ఋ', 12: 'ఎ', 13: 'ఏ', 14: 'ఐ', 15: 'ఒ', 16: 'ఓ', 17: 'ఔ', 18: 'క', 19: 'ఖ', 20: 'గ', 21: 'ఘ', 22: 'చ', 23: 'ఛ', 24: 'జ', 25: 'ఝ', 26: 'ఞ', 27: 'ట', 28: 'ఠ', 29: 'డ', 30: 'ఢ', 31: 'ణ', 32: 'త', 33: 'థ', 34: 'ద', 35: 'ధ', 36: 'న', 37: 'ప', 38: 'ఫ', 39: 'బ', 40: 'భ', 41: 'మ', 42: 'య', 43: 'ర', 44: 'ఱ', 45: 'ల', 46: 'ళ', 47: 'వ', 48: 'శ', 49: 'ష', 50: 'స', 51: 'హ', 52: 'ా', 53: 'ి', 54: 'ీ', 55: 'ు', 56: 'ూ', 57: 'ృ', 58: 'ె', 59: 'ే', 60: 'ై', 61: 'ొ', 62: 'ో', 63: 'ౌ', 64: '్', 65: '\\u200c'}\n"
          ]
        }
      ],
      "source": [
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "print(reverse_target_char_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjskNaet7bgj",
        "outputId": "8504bee8-046e-4e35-de60-1b76a315b823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18. 15.  7.  1. 13. 21. 12.  1. 14. 21.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.]\n",
            "[ 1. 43. 62. 20. 41. 55. 45. 36. 55.  2.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(enc_input_data[1])\n",
        "print(dec_input_data[1])\n",
        "print(dec_target_data[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui9pFxRvSdeT"
      },
      "source": [
        "For Validation and testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVGsHbTJn807",
        "outputId": "e729f96a-a860-4fc4-cfe0-3252890ea955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.  5.  3. 34. 55. 36. 52.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(val_dec_input_data[26])\n",
        "print(val_dec_target_data[26])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "X7q6xNssrRwb"
      },
      "outputs": [],
      "source": [
        "x_test = val_enc_input_data\n",
        "y_test = val_target_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL TRAINING "
      ],
      "metadata": {
        "id": "fsl1l9XK_jm0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AvI1fI7UOPMT"
      },
      "outputs": [],
      "source": [
        "class MyRNN(object):\n",
        "  def __init__(self,cell_type = 'RNN',in_emb = 32, hidden_size=32, learning_rate= 1e-3, \n",
        "               dropout=0.4,pred_type ='greedy',epochs = 10, batch_size = 32,beam_width = 5,\n",
        "               num_enc = 1,num_dec = 1):\n",
        "    \n",
        "    self.cell_type = cell_type\n",
        "    self.in_emb = in_emb\n",
        "    self.hidden_size = hidden_size\n",
        "    self.learning_rate = learning_rate\n",
        "    self.dropout = dropout\n",
        "    self.pred_type = pred_type\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.beam_width = beam_width\n",
        "    self.num_enc = num_enc\n",
        "    self.num_dec = num_dec\n",
        "\n",
        "  def build_fit(self,enc_input_data,dec_input_data,dec_target_data,x_test, y_test):\n",
        "    enc_inputs = Input(shape=(None, ),name = 'Enc_inputs')\n",
        "\n",
        "    # Add an Embedding layer expecting input vocab of size no_enc_tokens, and\n",
        "    # output embedding dimension of size in_enc.\n",
        "    enc_emb =  Embedding(no_enc_tokens, self.in_emb , mask_zero = True,name = 'Enc_emb')(enc_inputs)\n",
        "\n",
        "    enc_outputs = enc_emb\n",
        "    if self.cell_type == 'LSTM':\n",
        "      encoder_lstm = LSTM(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "      enc_outputs, state_h, state_c = encoder_lstm(enc_outputs)\n",
        "      encoder_states = [state_h, state_c]\n",
        "\n",
        "      # Add a LSTM layer with hidden_size internal units.\n",
        "      for i in range( 2, self.num_enc +1):\n",
        "        layer_name = ('Enc_hidden_%d') %i\n",
        "\n",
        "        encoder_lstm = LSTM(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "        enc_outputs, state_h, state_c = encoder_lstm(enc_outputs,initial_state = encoder_states)\n",
        "        encoder_states = [state_h, state_c]\n",
        "\n",
        "    elif self.cell_type == 'GRU':\n",
        "      encoder_gru = GRU(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "      enc_outputs, state_h = encoder_gru(enc_outputs)\n",
        "      encoder_states = [state_h]\n",
        "\n",
        "      for i in range(2, self.num_enc +1):\n",
        "        layer_name = ('Enc_hidden_%d') %i\n",
        "        encoder_gru = GRU(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "        enc_outputs, state_h = encoder_gru(enc_outputs, initial_state = encoder_states)\n",
        "        encoder_states = [state_h]  \n",
        "\n",
        "    elif self.cell_type == 'RNN':\n",
        "      encoder_rnn = SimpleRNN(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "      enc_outputs, state_h = encoder_rnn(enc_outputs)\n",
        "      encoder_states = [state_h]\n",
        "\n",
        "      for i in range(2, self.num_enc +1):\n",
        "        layer_name = ('Enc_hidden_%d') %i\n",
        "        encoder_rnn = SimpleRNN(self.hidden_size, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "        enc_outputs, state_h = encoder_rnn(enc_outputs, initial_state = encoder_states)\n",
        "        encoder_states = [state_h]  \n",
        "\n",
        "    # Set up the decoder, using `encoder_states` as initial state.\n",
        "    dec_inputs = Input(shape=(None,), name = 'Dec_inputs')\n",
        "    dec_emb_layer = Embedding(no_dec_tokens, self.hidden_size, mask_zero = True, name = 'Dec_emb')\n",
        "    dec_emb = dec_emb_layer(dec_inputs)\n",
        "    # We set up our decoder to return full output sequences,\n",
        "    # and to return internal states as well. We don't use the\n",
        "    # return states in the training model, but we will use them in inference.\n",
        "    dec_outputs = dec_emb\n",
        "    if self.cell_type == 'LSTM':\n",
        "      decoder_lstm = LSTM(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "      dec_outputs, _, _ = decoder_lstm(dec_outputs, initial_state = encoder_states)\n",
        "      \n",
        "      for i in range(2, self.num_dec +1):\n",
        "        layer_name = ('Dec_hidden_%d') %i\n",
        "\n",
        "        decoder_lstm = LSTM(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "        dec_outputs, _, _ = decoder_lstm(dec_outputs, initial_state = encoder_states)\n",
        "\n",
        "    elif self.cell_type == 'GRU':\n",
        "      decoder_gru = GRU(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "      dec_outputs, _ = decoder_gru(dec_outputs, initial_state = encoder_states)\n",
        "\n",
        "      for i in range(2, self.num_dec+1):\n",
        "        layer_name = ('Dec_hidden_%d') %i\n",
        "        decoder_gru = GRU(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "        dec_outputs, _ = decoder_gru(dec_outputs, initial_state = encoder_states)\n",
        "\n",
        "    elif self.cell_type == 'RNN':\n",
        "      decoder_rnn = SimpleRNN(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "      dec_outputs, _ = decoder_rnn(dec_outputs, initial_state = encoder_states)\n",
        "\n",
        "      for i in range(2, self.num_dec+1):\n",
        "        layer_name = ('Dec_hidden_%d') %i\n",
        "        decoder_rnn = SimpleRNN(self.hidden_size, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "        dec_outputs, _ = decoder_rnn(dec_outputs, initial_state = encoder_states)\n",
        "\n",
        "    decoder_dense = Dense(no_dec_tokens, activation='softmax', name = 'dense')\n",
        "    dec_outputs = decoder_dense(dec_outputs)\n",
        "\n",
        "    # Define the model that takes encoder and decoder input \n",
        "    # to output dec_outputs\n",
        "    model = Model([enc_inputs, dec_inputs], dec_outputs)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy'])\n",
        "  \n",
        "    model.fit(\n",
        "        [enc_input_data, dec_input_data],\n",
        "        dec_target_data,\n",
        "        batch_size=self.batch_size,\n",
        "        epochs=self.epochs,\n",
        "        callbacks = [WandbCallback()]\n",
        "        )\n",
        "    \n",
        "    encoder_model,decoder_model = self.inference_model(model)\n",
        " \n",
        "    global_total = 0\n",
        "    global_correct = 0\n",
        "    for i in range(len(val_source)):\n",
        "      #input_seq = val_enc_input_data[i : i + 1]\n",
        "      input_seq = x_test[i : i + 1]\n",
        "      result = self.decode_sequence(encoder_model,decoder_model,input_seq)\n",
        "      #target = val_target_texts[i]\n",
        "      target = y_test[i]\n",
        "      target = target[1:len(target)-1]\n",
        "      result = result[0:len(result)-1]\n",
        "      #print(\"Target: %s \\n Result: %s\" % (target, result))\n",
        "\n",
        "      if result.strip() == target.strip():\n",
        "        global_correct = global_correct + 1\n",
        "      \n",
        "      global_total = global_total + 1\n",
        "      accuracy_epoch = global_correct/global_total\n",
        "      if global_total % 50 == 0:\n",
        "        wandb.log({'epoch_accuracy' : accuracy_epoch})\n",
        "      #print(\"Accuracy: %s\" % (accuracy_epoch))\n",
        "    \n",
        "    val_accuracy = global_correct/global_total\n",
        "    #print(val_accuracy)\n",
        "\n",
        "\n",
        "    wandb.log({'val_accuracy' : val_accuracy})\n",
        "    \n",
        "  def inference_model(self,model):\n",
        "    enc_inputs = model.input[0]  # input_1\n",
        "    if self.cell_type == 'RNN' or self.cell_type == 'GRU':\n",
        "      enc_outputs, state_h_enc = model.get_layer('Enc_hidden_'+ str(self.num_enc)).output\n",
        "      encoder_states = [state_h_enc]\n",
        "      encoder_model = Model(enc_inputs, encoder_states)\n",
        "\n",
        "      dec_inputs = model.input[1]  # input_1\n",
        "      dec_outputs = model.get_layer('Dec_emb')(dec_inputs)\n",
        "      decoder_states_inputs = []\n",
        "      decoder_states = []\n",
        "\n",
        "      for i in range(1,self.num_dec +1):\n",
        "        decoder_state_input_h = keras.Input(shape=(self.hidden_size,))\n",
        "        curr_states_inputs = [decoder_state_input_h]\n",
        "        decoder = model.get_layer('Dec_hidden_'+ str(i))\n",
        "        dec_outputs, state_h_dec = decoder(dec_outputs, initial_state=curr_states_inputs)\n",
        "\n",
        "        decoder_states += [state_h_dec]\n",
        "        decoder_states_inputs += curr_states_inputs\n",
        "\n",
        "    elif self.cell_type == 'LSTM':\n",
        "      enc_outputs, state_h_enc, state_c_enc = model.get_layer('Enc_hidden_'+ str(self.num_enc)).output  # lstm_1\n",
        "      encoder_states = [state_h_enc, state_c_enc]\n",
        "      encoder_model = Model(enc_inputs, encoder_states)\n",
        "\n",
        "      dec_inputs = model.input[1]  # input_1\n",
        "      dec_outputs = model.get_layer('Dec_emb')(dec_inputs)\n",
        "      decoder_states_inputs = []\n",
        "      decoder_states = []\n",
        "\n",
        "      for i in range(1,self.num_dec +1):\n",
        "        decoder_state_input_h = keras.Input(shape=(self.hidden_size,))\n",
        "        decoder_state_input_c = keras.Input(shape=(self.hidden_size,))\n",
        "        curr_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "        decoder = model.get_layer('Dec_hidden_'+ str(i))\n",
        "        dec_outputs, state_h_dec, state_c_dec = decoder(dec_outputs, initial_state=curr_states_inputs)\n",
        "\n",
        "        decoder_states += [state_h_dec, state_c_dec]\n",
        "        decoder_states_inputs += curr_states_inputs\n",
        "\n",
        "\n",
        "    decoder_dense = model.get_layer('dense')\n",
        "    dec_outputs = decoder_dense(dec_outputs)\n",
        "    decoder_model = Model([dec_inputs] + decoder_states_inputs, [dec_outputs] + decoder_states)\n",
        "\n",
        "    return encoder_model,decoder_model\n",
        "\n",
        "  def decode_sequence(self,encoder_model,decoder_model,input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = [encoder_model.predict(input_seq)] * self.num_dec\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['B']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    while not stop_condition:\n",
        "        if self.cell_type == 'RNN' or self.cell_type == 'GRU':\n",
        "          dummy = decoder_model.predict([target_seq] + [states_value])\n",
        "          output_tokens, states_value = dummy[0],dummy[1:]\n",
        "          \n",
        "        elif self.cell_type == 'LSTM':  \n",
        "          dummy = decoder_model.predict([target_seq] + states_value)\n",
        "          output_tokens, states_value = dummy[0],dummy[1:]\n",
        "        \n",
        "        #print(output_tokens[0,:,:])\n",
        "        if self.pred_type == 'greedy':\n",
        "          beam_w = 1\n",
        "        elif self.pred_type == 'beam_search':\n",
        "          beam_w = self.beam_width\n",
        "        sampled_token_index = self.beam_search_decoder(output_tokens[0,:,:], beam_w)\n",
        "        sampled_token_index = sampled_token_index[beam_w-1][0]\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit when reaches max length or stop character is encountered.\n",
        "        if sampled_char == 'E' or len(decoded_sentence) > dec_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update state\n",
        "\n",
        "    return decoded_sentence\n",
        "  \n",
        "  def beam_search_decoder(self,data, k):\n",
        "    sequences = [[list(), 0.0]]\n",
        "    # read each step in sequence\n",
        "    for row in data:\n",
        "      all_candidates = list()\n",
        "      # expand each current candidate\n",
        "      for i in range(len(sequences)):\n",
        "        seq, score = sequences[i]\n",
        "        for j in range(len(row)):\n",
        "          candidate = [seq + [j], score - log(row[j])]\n",
        "          all_candidates.append(candidate)\n",
        "      # order all candidates by score\n",
        "      ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
        "      # select k best\n",
        "      sequences = ordered[:k]\n",
        "    return sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpH2nJGdCcZ0"
      },
      "source": [
        "## Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "y6v4kKgONH4q"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes', \n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "\n",
        "        'dropout': {\n",
        "            'values': [0.0, 0.1, 0.2]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-3, 1e-4]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [64, 128]\n",
        "        },\n",
        "        'in_emb': {\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'num_enc': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'num_dec': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'hidden_size':{\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'cell_type': {\n",
        "            'values': ['RNN', 'GRU', 'LSTM']\n",
        "        },\n",
        "        'dec_search': {\n",
        "            'values': ['beam_search', 'greedy']\n",
        "        },\n",
        "        'beam_width':{\n",
        "            'values': [3,5]\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "dC0C9Ol8QcW5",
        "outputId": "e90cd65e-c49d-4013-8961-aeeb7ceaea9b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 5sdtovzt\n",
            "Sweep URL: https://wandb.ai/girishrongali/assignment3/sweeps/5sdtovzt\n"
          ]
        }
      ],
      "source": [
        "# Initialize a new sweep\n",
        "sweep_id = wandb.sweep(sweep_config, entity=\"girishrongali\", project=\"assignment3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5QeYGKXmlKHr"
      },
      "outputs": [],
      "source": [
        "def train_sweep():\n",
        "  config_defaults = {\n",
        "        'dropout': 0.4,\n",
        "        'learning_rate': 1e-3,\n",
        "        'batch_size': 32,\n",
        "        'epochs' : 15,\n",
        "        'in_emb': 32,\n",
        "        'num_enc': 2,\n",
        "        'num_dec': 2,\n",
        "        'hidden_size': 32,\n",
        "        'cell_type': 'RNN',\n",
        "        'dec_search': 'beam_search',\n",
        "        'beam_width': 5\n",
        "        }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  wandb.init(config = config_defaults)\n",
        "  \n",
        "  # Config is a variable that holds and saves hyperparameters and inputs\n",
        "  config = wandb.config\n",
        "\n",
        "  wandb.run.name = str(config.cell_type)+ '_' + config.dec_search+'_bs_'+str(config.batch_size)\n",
        "  \n",
        "  model_rnn = MyRNN(cell_type = config.cell_type, in_emb = config.in_emb, hidden_size=config.hidden_size,\n",
        "                learning_rate= config.learning_rate, dropout=config.dropout,pred_type = config.dec_search,epochs = config.epochs,\n",
        "                batch_size = config.batch_size, beam_width = config.beam_width, num_enc = config.num_enc,num_dec = config.num_dec)\n",
        "  \n",
        "  model_rnn.build_fit(enc_input_data,dec_input_data,dec_target_data,x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c8d22292f6c044b18342d977614bfdea",
            "bfc528d51c784696930a846ba4689176",
            "8b661fa28c5840ea8e28225880968c1d",
            "ede8b7a20f234d328ad4c7ff14492786",
            "5689d95b78f147c4a7be82879ee260ad",
            "6f761ae93b7c45998f4a2775f9770411",
            "be8a8d022feb4198915e7c3293169340",
            "691a586182ea4cb3ba8035b30d919ed2",
            "e91387a405a6431abd5fe3c8f8a77a0f",
            "3fb99b0b440c4fcda989dd3ccac097a1",
            "2f011e7054bc4ee4b005431c2e47237f",
            "20fffe34f04042e893e2695609a125f3",
            "9f418e461a0845c8aebab7532a9c91fa",
            "77c5d92e0eef41ddbfee5ffe63ae32ef",
            "e587f280fa7b4b6ca6c4fb4ad6010bc7",
            "f174a472863847b68ae27205da519f96",
            "70cbaeae8ab4482aa4024fbe9a25ae54",
            "16578908758848a8a7f17e22f0796b8e",
            "0a031d952f4d48f684ea16d1d8d897d7",
            "579a9d1c65ee4ae7bec44605763882b4",
            "76e8905dffe046619808458103cd162c",
            "9cced5a0f5274d328d1e0fe32dcd08d5",
            "5b09032159d348d8866c36fc6070ad37",
            "be820bd008d64512b8429513ee93a7df"
          ]
        },
        "id": "AHqwHj8ukHYI",
        "outputId": "e98f3d95-7f36-49b9-9691-11ff5ba171f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: hxi6n58c\n",
            "Sweep URL: https://wandb.ai/girishrongali/assignment3/sweeps/hxi6n58c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dkqwwby8 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_search: beam_search\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_emb: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgirishrongali\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_090801-dkqwwby8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/girishrongali/assignment3/runs/dkqwwby8\" target=\"_blank\">vital-sweep-1</a></strong> to <a href=\"https://wandb.ai/girishrongali/assignment3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/girishrongali/assignment3/sweeps/hxi6n58c\" target=\"_blank\">https://wandb.ai/girishrongali/assignment3/sweeps/hxi6n58c</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Enc_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_emb (Embedding)            (None, None, 128)    3456        ['Enc_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Dec_emb (Embedding)            (None, None, 128)    8448        ['Dec_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Enc_hidden_1 (GRU)             [(None, None, 128),  99072       ['Enc_emb[0][0]']                \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " Dec_hidden_1 (GRU)             [(None, None, 128),  99072       ['Dec_emb[0][0]',                \n",
            "                                 (None, 128)]                     'Enc_hidden_1[0][1]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     8514        ['Dec_hidden_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 218,562\n",
            "Trainable params: 218,562\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "915/915 [==============================] - 35s 25ms/step - loss: 0.9428 - accuracy: 0.4298 - _timestamp: 1651741727.0000 - _runtime: 46.0000\n",
            "Epoch 2/15\n",
            "915/915 [==============================] - 23s 25ms/step - loss: 0.5004 - accuracy: 0.6845 - _timestamp: 1651741750.0000 - _runtime: 69.0000\n",
            "Epoch 3/15\n",
            "915/915 [==============================] - 23s 25ms/step - loss: 0.2898 - accuracy: 0.8133 - _timestamp: 1651741773.0000 - _runtime: 92.0000\n",
            "Epoch 4/15\n",
            "915/915 [==============================] - 23s 25ms/step - loss: 0.2098 - accuracy: 0.8642 - _timestamp: 1651741796.0000 - _runtime: 115.0000\n",
            "Epoch 5/15\n",
            "915/915 [==============================] - 23s 25ms/step - loss: 0.1699 - accuracy: 0.8892 - _timestamp: 1651741818.0000 - _runtime: 137.0000\n",
            "Epoch 6/15\n",
            "915/915 [==============================] - 23s 25ms/step - loss: 0.1456 - accuracy: 0.9049 - _timestamp: 1651741841.0000 - _runtime: 160.0000\n",
            "Epoch 7/15\n",
            "915/915 [==============================] - 23s 25ms/step - loss: 0.1286 - accuracy: 0.9159 - _timestamp: 1651741863.0000 - _runtime: 182.0000\n",
            "Epoch 8/15\n",
            "915/915 [==============================] - 23s 25ms/step - loss: 0.1161 - accuracy: 0.9242 - _timestamp: 1651741886.0000 - _runtime: 205.0000\n",
            "Epoch 9/15\n",
            "915/915 [==============================] - 23s 25ms/step - loss: 0.1055 - accuracy: 0.9308 - _timestamp: 1651741909.0000 - _runtime: 228.0000\n",
            "Epoch 10/15\n",
            "915/915 [==============================] - 23s 25ms/step - loss: 0.0976 - accuracy: 0.9357 - _timestamp: 1651741932.0000 - _runtime: 251.0000\n",
            "Epoch 11/15\n",
            "915/915 [==============================] - 23s 25ms/step - loss: 0.0902 - accuracy: 0.9408 - _timestamp: 1651741955.0000 - _runtime: 274.0000\n",
            "Epoch 12/15\n",
            "915/915 [==============================] - 22s 24ms/step - loss: 0.0841 - accuracy: 0.9446 - _timestamp: 1651741977.0000 - _runtime: 296.0000\n",
            "Epoch 13/15\n",
            "915/915 [==============================] - 22s 25ms/step - loss: 0.0787 - accuracy: 0.9485 - _timestamp: 1651742000.0000 - _runtime: 319.0000\n",
            "Epoch 14/15\n",
            "915/915 [==============================] - 22s 24ms/step - loss: 0.0736 - accuracy: 0.9518 - _timestamp: 1651742022.0000 - _runtime: 341.0000\n",
            "Epoch 15/15\n",
            "915/915 [==============================] - 22s 24ms/step - loss: 0.0696 - accuracy: 0.9541 - _timestamp: 1651742044.0000 - _runtime: 363.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8d22292f6c044b18342d977614bfdea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▇▇▇▇████████</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>epoch_accuracy</td><td>▁▆▆▇▇▇██████████████████████████████████</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.95414</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>epoch_accuracy</td><td>0.42867</td></tr><tr><td>loss</td><td>0.06962</td></tr><tr><td>val_accuracy</td><td>0.42865</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">vital-sweep-1</strong>: <a href=\"https://wandb.ai/girishrongali/assignment3/runs/dkqwwby8\" target=\"_blank\">https://wandb.ai/girishrongali/assignment3/runs/dkqwwby8</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220505_090801-dkqwwby8/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z9z2uiwl with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_search: beam_search\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_emb: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_100342-z9z2uiwl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/girishrongali/assignment3/runs/z9z2uiwl\" target=\"_blank\">kind-sweep-2</a></strong> to <a href=\"https://wandb.ai/girishrongali/assignment3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/girishrongali/assignment3/sweeps/hxi6n58c\" target=\"_blank\">https://wandb.ai/girishrongali/assignment3/sweeps/hxi6n58c</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Enc_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_emb (Embedding)            (None, None, 64)     1728        ['Enc_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_hidden_1 (GRU)             [(None, None, 32),   9408        ['Enc_emb[0][0]']                \n",
            "                                 (None, 32)]                                                      \n",
            "                                                                                                  \n",
            " Dec_emb (Embedding)            (None, None, 32)     2112        ['Dec_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Enc_hidden_2 (GRU)             [(None, None, 32),   6336        ['Enc_hidden_1[0][0]',           \n",
            "                                 (None, 32)]                      'Enc_hidden_1[0][1]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_1 (GRU)             [(None, None, 32),   6336        ['Dec_emb[0][0]',                \n",
            "                                 (None, 32)]                      'Enc_hidden_2[0][1]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_2 (GRU)             [(None, None, 32),   6336        ['Dec_hidden_1[0][0]',           \n",
            "                                 (None, 32)]                      'Enc_hidden_2[0][1]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     2178        ['Dec_hidden_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 34,434\n",
            "Trainable params: 34,434\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/15\n",
            "458/458 [==============================] - 35s 40ms/step - loss: 1.3012 - accuracy: 0.2406 - _timestamp: 1651745067.0000 - _runtime: 45.0000\n",
            "Epoch 2/15\n",
            "458/458 [==============================] - 18s 39ms/step - loss: 1.0034 - accuracy: 0.3856 - _timestamp: 1651745085.0000 - _runtime: 63.0000\n",
            "Epoch 3/15\n",
            "458/458 [==============================] - 18s 40ms/step - loss: 0.9049 - accuracy: 0.4425 - _timestamp: 1651745103.0000 - _runtime: 81.0000\n",
            "Epoch 4/15\n",
            "458/458 [==============================] - 18s 40ms/step - loss: 0.8227 - accuracy: 0.4861 - _timestamp: 1651745121.0000 - _runtime: 99.0000\n",
            "Epoch 5/15\n",
            "458/458 [==============================] - 18s 39ms/step - loss: 0.7557 - accuracy: 0.5249 - _timestamp: 1651745139.0000 - _runtime: 117.0000\n",
            "Epoch 6/15\n",
            "458/458 [==============================] - 18s 39ms/step - loss: 0.6984 - accuracy: 0.5578 - _timestamp: 1651745157.0000 - _runtime: 135.0000\n",
            "Epoch 7/15\n",
            "458/458 [==============================] - 18s 40ms/step - loss: 0.6480 - accuracy: 0.5866 - _timestamp: 1651745175.0000 - _runtime: 153.0000\n",
            "Epoch 8/15\n",
            "458/458 [==============================] - 18s 39ms/step - loss: 0.6053 - accuracy: 0.6105 - _timestamp: 1651745193.0000 - _runtime: 171.0000\n",
            "Epoch 9/15\n",
            "458/458 [==============================] - 18s 39ms/step - loss: 0.5707 - accuracy: 0.6292 - _timestamp: 1651745211.0000 - _runtime: 189.0000\n",
            "Epoch 10/15\n",
            "458/458 [==============================] - 18s 39ms/step - loss: 0.5407 - accuracy: 0.6459 - _timestamp: 1651745229.0000 - _runtime: 207.0000\n",
            "Epoch 11/15\n",
            "458/458 [==============================] - 18s 40ms/step - loss: 0.5147 - accuracy: 0.6603 - _timestamp: 1651745247.0000 - _runtime: 225.0000\n",
            "Epoch 12/15\n",
            "458/458 [==============================] - 18s 39ms/step - loss: 0.4932 - accuracy: 0.6732 - _timestamp: 1651745265.0000 - _runtime: 243.0000\n",
            "Epoch 13/15\n",
            "458/458 [==============================] - 18s 40ms/step - loss: 0.4753 - accuracy: 0.6839 - _timestamp: 1651745284.0000 - _runtime: 262.0000\n",
            "Epoch 14/15\n",
            "458/458 [==============================] - 18s 39ms/step - loss: 0.4595 - accuracy: 0.6939 - _timestamp: 1651745302.0000 - _runtime: 280.0000\n",
            "Epoch 15/15\n",
            "458/458 [==============================] - 18s 40ms/step - loss: 0.4455 - accuracy: 0.7029 - _timestamp: 1651745320.0000 - _runtime: 298.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e91387a405a6431abd5fe3c8f8a77a0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▅▅▆▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>epoch_accuracy</td><td>▁██▇▆▆▆▆▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.70287</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>epoch_accuracy</td><td>0.09292</td></tr><tr><td>loss</td><td>0.4455</td></tr><tr><td>val_accuracy</td><td>0.09326</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">kind-sweep-2</strong>: <a href=\"https://wandb.ai/girishrongali/assignment3/runs/z9z2uiwl\" target=\"_blank\">https://wandb.ai/girishrongali/assignment3/runs/z9z2uiwl</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220505_100342-z9z2uiwl/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 089hp274 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_search: beam_search\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_emb: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_110352-089hp274</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/girishrongali/assignment3/runs/089hp274\" target=\"_blank\">playful-sweep-3</a></strong> to <a href=\"https://wandb.ai/girishrongali/assignment3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/girishrongali/assignment3/sweeps/hxi6n58c\" target=\"_blank\">https://wandb.ai/girishrongali/assignment3/sweeps/hxi6n58c</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Enc_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_emb (Embedding)            (None, None, 32)     864         ['Enc_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Enc_hidden_1 (LSTM)            [(None, None, 128),  82432       ['Enc_emb[0][0]']                \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " Dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_hidden_2 (LSTM)            [(None, None, 128),  131584      ['Enc_hidden_1[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_1[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_1[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_emb (Embedding)            (None, None, 128)    8448        ['Dec_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Enc_hidden_3 (LSTM)            [(None, None, 128),  131584      ['Enc_hidden_2[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_2[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_2[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_1 (LSTM)            [(None, None, 128),  131584      ['Dec_emb[0][0]',                \n",
            "                                 (None, 128),                     'Enc_hidden_3[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_3[0][2]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     8514        ['Dec_hidden_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 495,010\n",
            "Trainable params: 495,010\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/15\n",
            "458/458 [==============================] - 42s 52ms/step - loss: 1.4244 - accuracy: 0.2158 - _timestamp: 1651748683.0000 - _runtime: 51.0000\n",
            "Epoch 2/15\n",
            "458/458 [==============================] - 24s 52ms/step - loss: 1.1526 - accuracy: 0.3236 - _timestamp: 1651748707.0000 - _runtime: 75.0000\n",
            "Epoch 3/15\n",
            "458/458 [==============================] - 24s 52ms/step - loss: 1.0441 - accuracy: 0.3629 - _timestamp: 1651748730.0000 - _runtime: 98.0000\n",
            "Epoch 4/15\n",
            "458/458 [==============================] - 23s 51ms/step - loss: 0.9954 - accuracy: 0.3922 - _timestamp: 1651748754.0000 - _runtime: 122.0000\n",
            "Epoch 5/15\n",
            "458/458 [==============================] - 24s 52ms/step - loss: 0.9533 - accuracy: 0.4171 - _timestamp: 1651748778.0000 - _runtime: 146.0000\n",
            "Epoch 6/15\n",
            "458/458 [==============================] - 23s 51ms/step - loss: 0.9202 - accuracy: 0.4338 - _timestamp: 1651748801.0000 - _runtime: 169.0000\n",
            "Epoch 7/15\n",
            "458/458 [==============================] - 24s 51ms/step - loss: 0.8902 - accuracy: 0.4489 - _timestamp: 1651748825.0000 - _runtime: 193.0000\n",
            "Epoch 8/15\n",
            "458/458 [==============================] - 24s 52ms/step - loss: 0.8636 - accuracy: 0.4625 - _timestamp: 1651748848.0000 - _runtime: 216.0000\n",
            "Epoch 9/15\n",
            "458/458 [==============================] - 23s 51ms/step - loss: 0.8364 - accuracy: 0.4778 - _timestamp: 1651748872.0000 - _runtime: 240.0000\n",
            "Epoch 10/15\n",
            "458/458 [==============================] - 24s 52ms/step - loss: 0.8121 - accuracy: 0.4920 - _timestamp: 1651748895.0000 - _runtime: 263.0000\n",
            "Epoch 11/15\n",
            "458/458 [==============================] - 24s 53ms/step - loss: 0.7903 - accuracy: 0.5043 - _timestamp: 1651748919.0000 - _runtime: 287.0000\n",
            "Epoch 12/15\n",
            "458/458 [==============================] - 24s 53ms/step - loss: 0.7687 - accuracy: 0.5172 - _timestamp: 1651748944.0000 - _runtime: 312.0000\n",
            "Epoch 13/15\n",
            "458/458 [==============================] - 24s 53ms/step - loss: 0.7478 - accuracy: 0.5303 - _timestamp: 1651748968.0000 - _runtime: 336.0000\n",
            "Epoch 14/15\n",
            "458/458 [==============================] - 24s 53ms/step - loss: 0.7266 - accuracy: 0.5428 - _timestamp: 1651748992.0000 - _runtime: 360.0000\n",
            "Epoch 15/15\n",
            "458/458 [==============================] - 24s 53ms/step - loss: 0.7060 - accuracy: 0.5546 - _timestamp: 1651749016.0000 - _runtime: 384.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70cbaeae8ab4482aa4024fbe9a25ae54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>epoch_accuracy</td><td>▁▁▁▁▄▃▃▄▄▄▇▇▇▆███▇▇▇▆▆▆▆▅▆▆▆▆▆▇▇▇▆▆▆▆▆▆▆</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.55459</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>epoch_accuracy</td><td>0.00283</td></tr><tr><td>loss</td><td>0.70599</td></tr><tr><td>val_accuracy</td><td>0.00282</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">playful-sweep-3</strong>: <a href=\"https://wandb.ai/girishrongali/assignment3/runs/089hp274\" target=\"_blank\">https://wandb.ai/girishrongali/assignment3/runs/089hp274</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220505_110352-089hp274/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d6wf4wi8 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_search: beam_search\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_emb: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_120706-d6wf4wi8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/girishrongali/assignment3/runs/d6wf4wi8\" target=\"_blank\">celestial-sweep-4</a></strong> to <a href=\"https://wandb.ai/girishrongali/assignment3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/girishrongali/assignment3/sweeps/hxi6n58c\" target=\"_blank\">https://wandb.ai/girishrongali/assignment3/sweeps/hxi6n58c</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Enc_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_emb (Embedding)            (None, None, 32)     864         ['Enc_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Enc_hidden_1 (GRU)             [(None, None, 128),  62208       ['Enc_emb[0][0]']                \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " Dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_hidden_2 (GRU)             [(None, None, 128),  99072       ['Enc_hidden_1[0][0]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_1[0][1]']           \n",
            "                                                                                                  \n",
            " Dec_emb (Embedding)            (None, None, 128)    8448        ['Dec_inputs[0][0]']             \n",
            "                                                                                                  \n",
            " Enc_hidden_3 (GRU)             [(None, None, 128),  99072       ['Enc_hidden_2[0][0]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_2[0][1]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_1 (GRU)             [(None, None, 128),  99072       ['Dec_emb[0][0]',                \n",
            "                                 (None, 128)]                     'Enc_hidden_3[0][1]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     8514        ['Dec_hidden_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 377,250\n",
            "Trainable params: 377,250\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/15\n",
            "915/915 [==============================] - 57s 43ms/step - loss: 1.3077 - accuracy: 0.2666 - _timestamp: 1651752493.0000 - _runtime: 67.0000\n",
            "Epoch 2/15\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 1.0319 - accuracy: 0.3686 - _timestamp: 1651752532.0000 - _runtime: 106.0000\n",
            "Epoch 3/15\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 0.9706 - accuracy: 0.4016 - _timestamp: 1651752572.0000 - _runtime: 146.0000\n",
            "Epoch 4/15\n",
            "915/915 [==============================] - 40s 43ms/step - loss: 0.9286 - accuracy: 0.4259 - _timestamp: 1651752611.0000 - _runtime: 185.0000\n",
            "Epoch 5/15\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 0.8896 - accuracy: 0.4500 - _timestamp: 1651752650.0000 - _runtime: 224.0000\n",
            "Epoch 6/15\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 0.8577 - accuracy: 0.4682 - _timestamp: 1651752689.0000 - _runtime: 263.0000\n",
            "Epoch 7/15\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 0.8286 - accuracy: 0.4843 - _timestamp: 1651752729.0000 - _runtime: 303.0000\n",
            "Epoch 8/15\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 0.7991 - accuracy: 0.5007 - _timestamp: 1651752768.0000 - _runtime: 342.0000\n",
            "Epoch 9/15\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 0.7706 - accuracy: 0.5166 - _timestamp: 1651752807.0000 - _runtime: 381.0000\n",
            "Epoch 10/15\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 0.7402 - accuracy: 0.5346 - _timestamp: 1651752846.0000 - _runtime: 420.0000\n",
            "Epoch 11/15\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 0.7108 - accuracy: 0.5521 - _timestamp: 1651752885.0000 - _runtime: 459.0000\n",
            "Epoch 12/15\n",
            "915/915 [==============================] - 40s 43ms/step - loss: 0.6856 - accuracy: 0.5666 - _timestamp: 1651752925.0000 - _runtime: 499.0000\n",
            "Epoch 13/15\n",
            "915/915 [==============================] - 40s 43ms/step - loss: 0.6623 - accuracy: 0.5803 - _timestamp: 1651752965.0000 - _runtime: 539.0000\n",
            "Epoch 14/15\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 0.6399 - accuracy: 0.5944 - _timestamp: 1651753004.0000 - _runtime: 578.0000\n",
            "Epoch 15/15\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 0.6180 - accuracy: 0.6078 - _timestamp: 1651753043.0000 - _runtime: 617.0000\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity=\"girishrongali\", project=\"assignment3\")\n",
        "wandb.agent(sweep_id, lambda : train_sweep())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Transliteration_without_attention_FINAL.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c8d22292f6c044b18342d977614bfdea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfc528d51c784696930a846ba4689176",
              "IPY_MODEL_8b661fa28c5840ea8e28225880968c1d"
            ],
            "layout": "IPY_MODEL_ede8b7a20f234d328ad4c7ff14492786"
          }
        },
        "bfc528d51c784696930a846ba4689176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5689d95b78f147c4a7be82879ee260ad",
            "placeholder": "​",
            "style": "IPY_MODEL_6f761ae93b7c45998f4a2775f9770411",
            "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "8b661fa28c5840ea8e28225880968c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be8a8d022feb4198915e7c3293169340",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_691a586182ea4cb3ba8035b30d919ed2",
            "value": 1
          }
        },
        "ede8b7a20f234d328ad4c7ff14492786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5689d95b78f147c4a7be82879ee260ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f761ae93b7c45998f4a2775f9770411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be8a8d022feb4198915e7c3293169340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "691a586182ea4cb3ba8035b30d919ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e91387a405a6431abd5fe3c8f8a77a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fb99b0b440c4fcda989dd3ccac097a1",
              "IPY_MODEL_2f011e7054bc4ee4b005431c2e47237f"
            ],
            "layout": "IPY_MODEL_20fffe34f04042e893e2695609a125f3"
          }
        },
        "3fb99b0b440c4fcda989dd3ccac097a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f418e461a0845c8aebab7532a9c91fa",
            "placeholder": "​",
            "style": "IPY_MODEL_77c5d92e0eef41ddbfee5ffe63ae32ef",
            "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "2f011e7054bc4ee4b005431c2e47237f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e587f280fa7b4b6ca6c4fb4ad6010bc7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f174a472863847b68ae27205da519f96",
            "value": 1
          }
        },
        "20fffe34f04042e893e2695609a125f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f418e461a0845c8aebab7532a9c91fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77c5d92e0eef41ddbfee5ffe63ae32ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e587f280fa7b4b6ca6c4fb4ad6010bc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f174a472863847b68ae27205da519f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70cbaeae8ab4482aa4024fbe9a25ae54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16578908758848a8a7f17e22f0796b8e",
              "IPY_MODEL_0a031d952f4d48f684ea16d1d8d897d7"
            ],
            "layout": "IPY_MODEL_579a9d1c65ee4ae7bec44605763882b4"
          }
        },
        "16578908758848a8a7f17e22f0796b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76e8905dffe046619808458103cd162c",
            "placeholder": "​",
            "style": "IPY_MODEL_9cced5a0f5274d328d1e0fe32dcd08d5",
            "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "0a031d952f4d48f684ea16d1d8d897d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b09032159d348d8866c36fc6070ad37",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be820bd008d64512b8429513ee93a7df",
            "value": 1
          }
        },
        "579a9d1c65ee4ae7bec44605763882b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76e8905dffe046619808458103cd162c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cced5a0f5274d328d1e0fe32dcd08d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b09032159d348d8866c36fc6070ad37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be820bd008d64512b8429513ee93a7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}